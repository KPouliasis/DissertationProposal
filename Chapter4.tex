\chapter{Curry -- Howard view of justification logic}
\label{proposal}
In this and the following chapter
we suggest reading a constructive necessity  
of a formula ($\Box A$) as  internalizing a notion 
of constructive truth of $A$ 
(a proof within a deductive system $I$) 
and validity of $A$
(a proof under an interpretation  $\llbracket A \rrbracket_J$ within some system $J$).  An example of such a relation is provided by the simply typed lambda calculus
(as $I$) 
and its implementation in $SK$ combinators (as $J$). 
We utilize justification logic to axiomatize the notion of 
validity-under-interpretation and, hence, 
treat  a  ``semantical'' notion in a purely
 proof-theoretic manner. We present the system  in 
Gentzen-style  natural deduction formulation  and provide reduction and expansion rules for the $\Box$ connective. Finally, we add proof-terms and proof-term equalities
to obtain a corresponding calculus ({\sf{Jcalc$^{-}$}}) in the next chapter.
The obtained system can be viewed as an extension of the Curry--Howard 
isomorphism with justifications.
We provide standard metatheoretic results  and suggest a 
programming language  interpretation in  languages with foreign function interfaces (\textit{FFI}s).

\section{Introduction: Necessity and Constructive Semantics}
In his seminal ``Explicit Provability and Constructive Semantics'' \cite{Artemov2001} Artemov developed a constructive, proof-theoretic semantics for 
\acs{BHK} proofs ~\cite{Troelstra1988} 
in what turned out to be the first development of a family of logics that we now call justification logic.
The general idea, upon which we build our calculus, is that semantics of a deductive system $I$ can be viewed in a solely proof-theoretic manner 
as mappings of proof constructs of $I$ into another proof system $J$ (which we call justifications).
As an example one could think  $I$  being  Heyting arithmetic and $J$ some  ``stronger'' system 
(e.g. a classical axiomatization of Peano arithmetic, a classical or intuitionistic set theory etc). 
 In Artemov's work $I$ is assumed to be
based on intuitionistic logic and $J$  on classical logic. 
We, initially,  mute such assumptions to focus exclusively 
on the mechanics of necessity in this framework.
We recover them later and study  their relation  to  
the Rule of Necessitation for our system.
What's more,  such a semantic relation can be treated 
logically giving  rise to a modality of explicit necessity. 
Different sorts of necessity
($K$, $D$, $S4$, $S5$) have been offered  an explicit counterpart under the umbrella of justification logic. Some of them have been studied within a
Curry--Howard setting ~\cite{ArtBon07LFCS}. Our work
focuses on  $K$ modality and  should be viewed as the  counterpart of ~\cite{Bellin2001} with justifications as we explain in \ref{relat}.
\subsection{Deductive Systems, Validity and Necessity}
Following a framework championed by Lambek \cite{Lambek1968,Lambek1969}, let us  assume two deductive systems $I$ 
(with propositional universe $U_I$, 
a possibly non-empty signature of axioms $\Sigma_I$ and an entailment relation $\Sigma_I;\Gamma\vdash_{I}A$) and $J$ 
(resp. with  $U_J$, $\Sigma_J$ and $\Sigma_J;\Delta\vdash_J \phi$). We will be using Latin letters for the formulae of $I$ and Greek letters for the formulae of $J$.
We will be omitting the $\Sigma$ signatures when they are not relevant.

For the  entailment relations of the two systems we require the following elementary principles\footnote{We are not excluding other connectives but by imposing
such minimal requirements we show that ``necessity'' ($\Box$) connective can be treated generically and orthogonally of the presence of other connectives}:
\begin{enumerate}
	\item \textit{Reflexivity}. In both relations $\Gamma$ and $\Delta$ are multisets of formulas (contexts) that enjoy reflexivity:
	$$A \in \Gamma \Longrightarrow \Gamma\vdash_{I}A$$ $$\phi \in \Delta \Longrightarrow \Delta\vdash_{J}\phi$$
	\item \textit{Compositionality}.  Both relations are closed under deduction composition:  
	$$\Gamma\vdash_I A \text{\ and\ } \Gamma^{'},A\vdash_{I} B \Longrightarrow \Gamma,\Gamma^{'}\vdash_I B $$  
	$$\Delta\vdash_J\phi \text{\ and\ } \Delta^{'},\phi\vdash_{J} \psi \Longrightarrow \Delta,\Delta^{'}\vdash_J \psi$$ 
	\item \textit{Top}. Both systems have a distinguished top formula $\top$ for which under any $\Gamma$, $\Delta$: $$\Gamma\vdash_{I}\top_I \text{\ and \ }
	\Delta \vdash_J\top_J$$
\end{enumerate}

Now we can define: 
\begin{definition}Given a deductive system $I$, an   \textit{interpretation for $I$}, noted by $\llbracket\bullet \rrbracket_J$, is a pair
	$(J,\llbracket\bullet\rrbracket)$ of a deductive  system $J$ together
	with a (functional) mapping $\llbracket \bullet \rrbracket: U_I\rightarrow U_J$ on propositions of $I$ into propositions of $J$ extended to multisets of 
	formulae of $U_I$ with the following properties:
	\begin{enumerate}
		\item \textit{Top preservation}. $\llbracket\top_I \rrbracket = \top_J$
		% \item\textit{structural interpretation of connectives}. The interpretation of compound formulas built upon primitive connectives of $I$ is structural.
		% E.g. Given $Con$ is a binary primitive connective of $I$ then in prefix notation we want:  
		% $\llbracket  Con(A, B) \rrbracket_J = \llbracket\ Con\rrbracket (\llbracket A \rrbracket , \llbracket \ B \rrbracket$ where $\llbracket Con\rrbracket$ is a connective in $J$.
		\item \textit{Structural interpretation of contexts}. For  $\Gamma$ contexts of the form $A_1,\ldots, A_n$:
		$$\llbracket\Gamma \rrbracket=\llbracket A_1  \rrbracket,\ldots,  \llbracket A_n\rrbracket$$ (trivially empty contexts map to empty contexts. 
		As in \cite{Lambek1968} they can be treated as 
		the $\top$ element).
	\end{enumerate}
\end{definition}
\begin{definition}Given a deductive system $I$  and an  interpretation $\llbracket\bullet\rrbracket_J$ for $I$ we define
	a \textit{corresponding validation of a deduction $\Sigma_I;\Gamma\vdash_I A$}  
	as a deduction $\Sigma_J;\Delta\vdash_{J} \phi$ in $J$ such that $\llbracket A \rrbracket=\phi$ and $\Delta=\llbracket \Gamma \rrbracket $ . We will be writing
	$ \llbracket \Sigma_I;\Gamma\vdash_I A\rrbracket_J$ to denote such a validation.
\end{definition}
\begin{definition}
	Given a deductive system $I$, we say that an interpretation  $\llbracket\bullet \rrbracket_J$  is \textit{logically complete} when  for
	all purely logical deductions $\mathcal{D}$ (i.e. deductions that make no use of $\Sigma_I$) in $I$ 
	there exists a corresponding (purely logical) validation $\llbracket\mathcal{D}\rrbracket$ in $J$.
	i.e. $$\forall \mathcal{D}. \ \mathcal{D}:\Gamma\vdash_I A \Longrightarrow \exists \llbracket\mathcal{D}\rrbracket: \llbracket \Gamma\vdash A\rrbracket_J$$
\end{definition}
\footnote{Note, that we require existence but not uniqueness. Nevertheless, if we treat deductive systems  in a proof irrelevant manner as preorders 
the above definition gives uniqueness vacuously. In a more refined approach where $I$ and $J$ are viewed as  categories of proofs  the above ``logical completeness''  
translates to the requirement that if the set of (purely logical) arrows $Hom_I(\Gamma,A)$ is non empty  then $Hom_J(\llbracket\Gamma\rrbracket,\llbracket A\rrbracket_J)$ 
cannot be empty (i.e. that $\llbracket\bullet \rrbracket_J$ can be extended to a functor). We leave a complete categorical semantics of our logic 
for future work but we expect   a generalization of the 
endofunctorial interpretations of $K$ modality appearing in \cite{Bellin2001,kavvos2016system}.} 


Examples of triplets ($I$, $J$, $\llbracket\bullet \rrbracket_J$) of logical systems that fall under the definition above are: any intuitionistic system mapped 
to a classical one under the embedding $\llbracket A \supset B\rrbracket= \tilde{\neg} A \tilde{\vee} B$ where  $\tilde{\neg}$
and $\tilde{\vee}$ are classical connectives, the opposite direction under double negation translation, 
an  intuitionistic system  mapped to another intuitionistic system (i.e. a mapping of atomic formulas of $I$ to atomic formulas of $J$ extended naturally to the intuitionistic connectives 
or, simply, the identity mapping) etc.  A vacuous validation  (when $\llbracket\bullet  \rrbracket_J$ maps everything to $\top$) gives another example. 

The main thesis that is exposed in this chapter is that this notion of ``double proof'' (reasoning about proofs that exists in two related systems) 
provides for an understanding of necessity in proof theoretic terms. In addition, we argue, 
that this is the driver of (at least) the simplest
form of necessity ($K$) that appears in justification logic (\textit{necessity as internalization}).
We will focus on the case where $I$ (the propositional part of our logic) is based on the implicative fragment of intuitionistic logic and show how justification logic
provides for an axiomatization of such logically complete interpretations $\llbracket\bullet\rrbracket_J$ of  implicative intuitionistic logic.
In what follows we provide  a natural deduction for
an intuitionistic system $I$ (truth), an axiomatization/specification of   $\llbracket \bullet \rrbracket_J$ (treated abstractly as a function symbol on types) and a treatment 
of basic necessity that relates the two deductions by internalizing  a  notion of ``double truth'' (proof in $I$  and  existence of corresponding validation in  $J$).
\section{Judgments of Jcalc$^{-}$}
\label{lsjcalc}

We aim for a reading of necessity that internalizes a notion of ``double proof''  in two deductive systems.
Motivated by the discussion and definitions in the previous section we will treat the notion of interpretation abstractly -- as a function symbol on types -- 
and axiomatize in accordance. Intuitively we want:
$$\Box  A\  {\sf true} :=  A\ {\sf true}\   \& \ A\ {\sf valid} = A{\sf\  true\  in\  I}\  \& \  \llbracket  A \rrbracket \ {\sf true\  in\  J}$$
We will be dropping indexes $I$, $J$ since they can be inferred by the different kinds of assumption  contexts. In addition, we  omit signatures 
$\Sigma$ since they do not offer anything from a logical perspective.

Logical entailment for the proposed  $\Box$ connective can be  summarized  easily given our previous discussion.
Given a deduction $\mathcal{D}:A \vdash B$ and  the existence of validation $\llbracket\mathcal{D}\rrbracket:\llbracket A \rrbracket\vdash \llbracket B\rrbracket$ then 
given $\Box A$ (i.e.  a proof of a  $\vdash A$ and a validation $\vdash \llbracket A \rrbracket$)
we obtain a double proof of $B$ (and hence, $\Box B$) by \textit{compositionality} of the underlying systems.  
Using standard, proof tree notation with labeled assumptions we formulate our rule of the connective in natural deduction:

\mbox{\small
	\begin{mathpar}
		\inferrule* [right=$I_{\Box B} E^{x,s}_{\Box A}$]{{\infer*{\Box  A}{}}
			\\{\inferrule*{}
				{\inferrule*[vdots=1.5em, right=$x$]{ }{ A}\\\\
					\inferrule*[]{}{ B}}}\\
			{\inferrule*{}
				{\inferrule*[vdots=1.5em, right=${s}$]{ }{\llbracket   A\rrbracket}\\\\
					\inferrule*[]{}{\llbracket  	B\rrbracket}}}
		}{\Box  B} 
		
	\end{mathpar}
}
We can, easily, generalize to $\Box$ed contexts (of the form $\Box A_1, \ldots,  \Box A_i$) of arbitrary length:
\\
\mbox{\small
	\begin{mathpar}
		\inferrule*[right=$I_{\Box B}E^{\vec{x},\vec{s}}_{\Box A_1\ldots \Box A_i} $] {{\infer*{\Box  A_1}{}}\\{\ldots}\\
			{\infer*{\Box  A_i}{}}\\	{\inferrule*{}
				{\inferrule*[vdots=1.5em, right=$\vec{x}$]{ }{\Gamma': A_1,\ldots  A_i}\\\\
					\inferrule*[]{}{ B}}}\\
			{\inferrule*{}
				{\inferrule*[vdots=1.5em, right=$\vec{s}$]{ }{\llbracket \Gamma'\rrbracket:\llbracket  A_1\rrbracket,\ldots \llbracket  A_i\rrbracket}\\\\
					\inferrule*[]{}{\llbracket  B\rrbracket}}}
		}{\Box  B}
		
	\end{mathpar}
}
\\
We read as ``Introducing $\Box B$ after eliminating $\Box A_1 \ldots \Box A_i $ crossing out (vectors of) labels $\vec{x}, \vec{s}$ ". 
Interestingly, the same rule eliminates boxes  and introduces new ones. 
This  is not surprising for $K$ modality (it is a left-right rule as we will see (\ref{seqcalc}).
See also discussion in \cite{Bellin2001,Bierman2000}). We will be referring to this rule  as ``$\Box$ Intro--After--Elim'' or, simply $\Box_{IE}$, from now on.
%Moreover, it has a very clear computational reading in our system which we will be explaining. 
%In a nutshell, theorems of $K$ correspond to programs that consume (eliminate) congruences on subterms to construct construct congruences on larger terms. In that sense, the elim-intro mix is quite natural.

Note that we define the $\Box$ connective negatively, yet (pure) introduction rules for the $\Box$ 
connective are  derivable. 
Such are instances of the previous Intro--After--Elim rule when 
$\Gamma'$ is empty which conforms exactly with the idea  of necessity internalizing double theoremhood.

\mbox{
	\begin{mathpar}	
		\inferrule*[right=$I_{\Box  B}$]{{\vdash B }\\{\vdash \llbracket B \rrbracket}}{\Box B}
	\end{mathpar}}
	
	In the next section, we provide the whole calculus in natural deduction format. As expected
	we will extend the implicational fragment of intuitionistic logic with 
	\begin{itemize}
		\item Judgments about validity (justification logic).
		\item Judgments that relate truth and validity (modal judgments).
	\end{itemize}
	%The former judgments could be viewed as a "Hilbert-style" encoding of the underlying intuitionistic one. Justification logic uses a combinatory calculus (extended with classical combinators) to represent logical principles (constants) in this second level. We follow the same route, obtaining a Curry Howard Correspondance for Justification logic under this new ``necessity as double proof" doctrine. 
	\subsection{Natural Deduction for Jcalc$^{-}$}
	The treatment of necessity in the previous section is completely orthogonal to the underlying systems \
	(it just assumes the basic requirements stated for the behavior $\llbracket\dot\rrbracket$). 
	In this section we will provide a full calculus and in congruence with justification logic we will
	assume that the underlying system ($I$) is a fragment of intuitionistic logic (the `negative' to be precise).
	The host theory $J$ can still remain unspecified, but the choice of $I$ informs for some specifications (to preserve
	completeness of logical deductions).   

	Following type theory conventions,  we first provide rules underlying type construction, then  rules for  well-formedness of (labeled) assumption contexts and rules  introducing and eliminating connectives. 
	The rules below should be obvious except for small caveat.
	 On the one hand, the type universe of $U_I$ and the proof trees of $I$ are 
	inductively defined as usual; on the other 
	hand, the host theory $J$ (its corresponding universe, connectives and  proof trees) is  ``black boxed''. What we actually axiomatize are the properties that all
	(logic preserving) interpretations of $I$ should conform to, independently of the specifics of the host theory. 
	Validity judgments should thus be read  as specifications
	of provability (existence of proofs) of any candidate $J$. 
	
	When we write $\llbracket \Gamma\rrbracket\vdash\llbracket\phi\rrbracket$ it reads as there exists derivation
	$\mathcal{D}$ : $\Delta\rrbracket\vdash_{J}\psi\rrbracket$ s.t. $\Delta=\llbracket\Gamma\rrbracket$ and $\psi = \llbracket \phi\rrbracket$ )
	
	We use ${\sf Prop_0}$  to denote  the type universe of $I$ and $\llbracket \sf Prop_0\rrbracket $ to denote its image under an interpretation, ${\sf Prop_1}$ denotes   modal (``boxed'') types
	and ${\sf Prop}$  the union of ${\sf Prop_0, Prop_1}$. We write $P_k$ with $k$ ranging in some subset of natural numbers to denote atomic propositions in $I$. 
	
	
	
	\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Type Universe(s)}]
		\mbox{\small
			\begin{mathpar}
				\inferrule*[right= Atom] { } {P_k \in {\sf Prop_0}}
				\and
				\inferrule*[right=Top] { } {\top \in {\sf Prop_0}}
				\and
				\inferrule*[right=Conj] {{ A \in {\sf Prop_i }}\\ { B \in {\sf Prop_j}}} {  A \wedge B \in {\sf Prop_{max(i,j)}} } 
				%\inferrule*[right=Bot] { } {\bot \in {\sf Prop_0}} 
				%\and
				\and
				\inferrule*[right=Box] { A \in{\sf Prop_{0} }} {\Box  A\in{\sf Prop_{1}} }
				%\and
				%\inferrule*[right= Arr] {{ A \in {\sf Prop_{i} }}\\ { B \in {\sf Prop_{j}}}} { A\supset  B\in {\sf Prop_{max(i,j)}}}
				\and
				\inferrule*[right= Arr] {{ A \in {\sf Prop_i }}\\ { B \in {\sf Prop_j}}} { A\supset  B\in {\sf Prop_{max(i,j)}}}
				\and
				\inferrule*[right=Brc] { A \in {\sf Prop_0 }} {\llbracket  A\rrbracket \in {\sf \llbracket Prop_{0}\rrbracket}}
				%\and
				%\inferrule*[right=Brc $\supset$ Eq] {\llbracket A\supset\psi\rrbracket \in {\sf \llbracket Prop_{0}\rrbracket }} {\llbracket A\supset \psi\rrbracket=\llbracket A\rrbracket\supset \llbracket\psi\rrbracket :{\llbracket\sf Prop_{0}\rrbracket} }
			\end{mathpar}
		}
	\end{mdframed}
	
	%From now on we will be omitting the type construction derivations and write, informally, $ A\in U$( or, for multisets, $\Gamma\in U$) denoting the unique (\ref{bftu}) such derivation(s). 
	
	
	
	
	For labeled contexts of assumptions we require standard wellformedness conditions (i.e. uniqueness of labels).
	We use letters $x_i$, or simply $x$, for labels of  contexts with assumptions in $\sf Prop_0$, $x_i'$ or simply $x'$ for contexts with assumptions in   $\sf Prop_1$ and $s_i$, or simply $s$,  
	for $\sf \llbracket Prop_0 \rrbracket$ contexts. 
	We use $\circ$ for the empty context of ${\sf Prop_0}$ and ${\sf Prop_1}$ and  $\dagger$ for the empty context of ${ \llbracket {\sf Prop_0}\rrbracket}$.
	%We ``overload" the use of $\in$ symbol and write $x\not\in\Gamma$ to denote that ``the label $x$ is not present in the domain of $\Gamma$".
	We abuse notation and write $x:A\in\Gamma$ (or, similarly, $s:\llbracket A\rrbracket\in\Delta$) to denote that the label $x$ is assigned type $A$ in $\Gamma$; or $\Gamma\in {\sf Prop_0}$ 
	(resp. $\Gamma \in {\sf Prop_1}$, $\Delta\in {\sf \llbracket Prop_0\rrbracket}$)  
	to denote that  $\Gamma$ is a wellformed context  with  co--domain of elements in ${\sf Prop_0}$ (resp. in ${\sf Prop_1}$, $\llbracket {\sf Prop_0}\rrbracket$).
	For $\Gamma \in {\sf Prop_0}$ we define  $\llbracket \Gamma\rrbracket$ as  the lifting of the context $\Gamma$ through the $\llbracket \bullet \rrbracket$  symbol 
	(with appropriate renaming of variables -- e.g. $x_i\rightsquigarrow s_i$). For the vacuous case  when $\Gamma$  is  empty 
	we require $\llbracket\circ \rrbracket = \dagger$ to be well formed.
	
	\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Context Wellformedness}]
	\mbox{\footnotesize
	\begin{mathpar}
	\inferrule*[right=\small{Nil}] { }{\Turn {\circ} {\sf wf}}
	\and
	\inferrule*[right=$\Gamma$-Ext] { {\Gamma\in {\sf Prop_0}}\\ { A \in {\sf Prop_0}} \\{x\not\in \Gamma}}{{\Gamma, x: A}\in {\sf Prop_0}}
	\and
	%\and
	%\inferrule*[right=\small{Nil}] { } {\Turn {\circ} {\sf\llbracket wf\rrbracket}}
	\inferrule*[right=$\llbracket$\small{ Nil} $\rrbracket$]{ }{\Turn {\dagger= \llbracket \circ \rrbracket} {\sf\llbracket wf\rrbracket}}
	\and
	\inferrule*[right=$\llbracket\Gamma\rrbracket$] { {  \Gamma  \in {\sf  Prop_0}}} {\llbracket \Gamma \rrbracket \in { \llbracket \sf Prop_0 \rrbracket}}
	\end{mathpar}}
	\end{mdframed}
	%Certain basic facts about well formed contexts are shown in the appendix \ref{bfcw}. 
	In the following entry we define proof trees (in turnstile representation) of the intuitionistic source theory $I$.  For all following rules we assume $\Gamma, A,B \in {\sf Prop_0}$:
	\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Truth  $\Gamma, A,B \in {\sf Prop_0}$ }]
		\label{jots}
		\mbox{\small
			\begin{mathpar}
				\inferrule*[right=$\Gamma_0$-Refl] {x: A \in \Gamma}{\Turn {\Gamma} { A}}
				\and
				\inferrule*[right=$\top_0$I] { }{\Turn {\Gamma} { \top}}
				\and
				\inferrule*[right=$\supset_0$I] {{\Turn {\Gamma, x: A} { B}}} {\Turn {\Gamma} {   A\supset  B}}
				\and
				\inferrule*[right=$\supset_0$E] {{\Turn {\Gamma} { A\supset  B}}\\{\Turn {\Gamma} { A}}} {\Turn {\Gamma} {   B}}
				
				%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
			\end{mathpar}}
		\end{mdframed}
		
		For the calculus of interpretation (validity) we demand context reflexivity, compositionality and logical completeness with respect to  intuitionistic implication.
		Logical completeness is specified axiomatically, since the host theory is ``black boxed''. 
		Following justification logic, we use an axiomatic characterization of combinatory logic (for $\supset$) together 
		with the requirement that the interpretation preserves modus ponens:
		\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Validity with {$\Delta\in \llbracket {\sf Prop_0} \rrbracket$}}]
			\label{jov}
			\mbox{\footnotesize
				\begin{mathpar}
					\inferrule*[right=$\Delta$-Refl] {s:\llbracket  A\rrbracket \in \Delta}{\Turn {\Delta} {\llbracket  A\rrbracket}}
					\and
					\inferrule*[right=Ax$_1$] { } {\Turn {\Delta} {\llbracket  \top\rrbracket}}
					\and
					\inferrule*[right=  Ax$_2$]{  A, B \in {\sf Prop_0} }   {\Delta\vdash \llbracket   A \supset (B \supset   A)\rrbracket }
					\and
					\inferrule*[right=  Ax$_3$]{ {  A,B, C \in {\sf Prop_0}}}{\Delta\vdash\llbracket   A\supset (B \supset C) \supset ((  A\supset B) \supset (  A \supset C))\rrbracket}
					\and
					\inferrule*[right=MP] {{\Turn {\Delta} { \llbracket  A \supset  B \rrbracket}}\\ {\Turn{\Delta} {\llbracket  A \rrbracket}}}{\Turn {\Delta} {\llbracket  B\rrbracket}}
				\end{mathpar}}
			\end{mdframed}
			
			Finally, we have judgments in the $\Box$ed universe (${\sf Prop_1}$). These are context reflection, the $\Box$ Intro-After-Elim rule, and the rules for intuitionistic implication between $\Box$ed types
			\footnote{The implication and elimination rules in ${\sf Prop_1}$ actually coincide with the ones
				in ${\sf Prop_0}$ since we are focusing on the case where $I$ is intuitionistic. This need not necessarily be the case as we have explained. Intuitionistic  implication among $\Box$ types should be read as
				``double proof of $A$ implies double
				proof of $B$'' and would still be defined even if we did not observe any kind of  implication in $I$. Similarly, one could provide intuitionistic conjunction or disjunction between $\Box$ types independently of 
				$I$ and, vice versa, one could add connectives in $I$ that are not observed between $\Box$ed types.}. 
			\begin{mdframed}[nobreak=true, frametitle={\footnotesize Judgments on Necessity with $\Gamma\in {\sf Prop_1} \text{,{\ \sf length}}(\Gamma)=i\text{,\ }
					\ 1\le k\le i  \text{\ and, }\Gamma^{\prime},A, A_k,  B\in {\sf Prop_0}$ }]
				\mbox{\footnotesize
					\begin{mathpar}
						\inferrule*[right=$\Gamma_1$-Refl] {x^{\prime}: \Box A \in \Gamma}{\Turn {\Gamma} {\Box A}}
						\and
						\inferrule*[right=$I_{\Box B}E^{\vec{x},\vec{s}}_{\Box A_1\ldots \Box A_i}$]{{(\forall  A_i \in \Gamma'. \ \Turn {\Gamma}{\Box  A_i})}\\{\Turn {\Gamma'} { B}}\\{\Turn {\llbracket \Gamma' \rrbracket} {\llbracket  B\rrbracket} }} {\Turn {\Gamma}\Box  B}
						\and
						\inferrule*[right=$\supset_1$I] {{\Turn {\Gamma, x^{\prime}: \Box A} { \Box B}}} {\Turn {\Gamma} {   \Box A\supset  \Box B}}
						\and
						\inferrule*[right=$\supset_1$E] {{\Turn {\Gamma} { \Box A\supset  \Box B}}\\{\Turn {\Gamma} { 
									\Box A}}} {\Turn {\Gamma} {  \Box B}}
					\end{mathpar}}
				\end{mdframed}
				
				%Observe, that as a consequence of our restrictions in the universe of propositions, all instances of the previous rule have $\Gamma'\in {\sf Prop_0}$. 
				%This is not a premise of the rule since it is can be proven, easily, meta--theoretically.
				\subsubsection{(Pure) $\Box I$ as derivable rule}
				We stress here that $\Box$ can be introduced positively with the previous rule with $\Gamma^{'}=\circ$. The first premise reduces to a simple requirement that $\Gamma\in{\sf Prop_1}$.
				
				\mbox{\small
					\begin{mathpar}
						\inferrule*[right=$I_{\Box A}$]{{\Turn {\circ} { A}}\\{\Turn {\dagger} {\llbracket  A\rrbracket} }} {\Turn {\Gamma}\Box  A}
					\end{mathpar}}
					\subsubsection{A simple derivation}
					\label{smpdv}
					We show here that the $K$ axiom of modal logic is a theorem (omitting some obvious steps). In the following {\small $$\Gamma := x_1^{\prime}:\Box (A\supset B),x_2^{\prime}:\Box A, \ \Gamma^{\prime}=x_1:A\supset B, x_2:A,
						\ \llbracket \Gamma^\prime\rrbracket= s_1:\llbracket A \supset B\rrbracket, s_2:\llbracket A\rrbracket$$}
					\mbox{\small
						\begin{mathpar}
							\inferrule*[right=$\supset_1$I]{\inferrule*[right=$\supset_1$I]{
									\inferrule*[right= $I_{\Box A}E^{x_1,x_2,s_1,s_2}_{\Box A\supset B, \Box A}$]{{\inferrule*[]{}{\Gamma \vdash \Box ( A \supset B)}}\\
										{\inferrule*[]{}{ \Gamma\vdash \Box  A }}\\{\inferrule*[]{}{\Gamma^\prime\vdash B}}\\{\inferrule*[]{}{\llbracket\Gamma^\prime\rrbracket\vdash \llbracket B\rrbracket}}} {\Box ( A\supset B), \Box  A \vdash \Box B }} {\Box ( A\supset B) \vdash \Box  A \supset \Box B}}{\circ\vdash \Box ( A\supset B)\supset \Box  A \supset \Box B}
						\end{mathpar}
					}
\subsection{Logical Completeness, Admissibility of Necessitation and Completeness with respect to Hilbert Axiomatization}
\label{completness}
Here we give a Hilbert  axiomatization  of the $\supset$ fragment of intuitionistic $K$ logic in order to compare it with our system. Here  $\vdash^{\mathcal{H}}$ captures the textbook (metatheoretic)
notion of ``deduction from assumptions'' in a Hilbert style axiomatization. We assume the restriction of the system to formulas up to modal degree $1$.
\begin{mdframed}[nobreak=true,frametitle={\footnotesize Hilbert Style Formulation}]
	\mbox{\footnotesize
		\begin{mathpar}
			\inferrule*[left=ax1.]{}{ A\supset (B \supset  A)}
			\and
			\inferrule*[left=ax2.]{}{ (A\supset (B \supset C) )\supset (( A\supset B) \supset ( A \supset C))}
			\and
			\inferrule*[left=K.]{}{\Box ( A\supset B)\supset\Box  A \supset \Box B}
			\and
			\inferrule*[left=MP]{ { A \supset B}\\ { A}}{B}
			\and
			\inferrule*[left=Nec]{\vdash^{\mathcal{H}}  A}{\Box  A}
		\end{mathpar}}
	\end{mdframed}
	
	It is easy to verify that axioms $1$, $2$ are derived theorems of {\sf Jcalc$^{-}$} in ${\sf Prop_0}$. The rule Modus Ponens is also admissible trivially, whereas axiom $K$  was  
	shown to be a theorem in the previous section (\ref{smpdv}). The rule of Necessitation is not obviously admissible though. In our reading of necessity the
	admissibility of this rule is directly related to the requirement of ``logical completeness of the interpretation'' i.e. preservation of logical theoremhood.  
	In general, adding more connectives in $I$ would require additional specifications for the host theory to obtain necessitation.
	
	The steps of the proof are given in the Appendix, but this is essentially  the ``lifting lemma'' in justification logic \cite{Artemov2001}. 
	The proof fully depends on
	the provability requirements imposed in the $\llbracket{\sf Prop_0}\rrbracket$ fragment.
	\begin{theorem}[$\Box$Lifting Lemma]
		In {\sf Jcalc$^{-}$}, for every  $\Gamma,   A \in {\sf Prop_0}$ if  $\Gamma\vdash A$ then  $\llbracket \Gamma\rrbracket\vdash\llbracket A\rrbracket $ and, hence, $\Box\Gamma \vdash \Box   A$.
	\end{theorem}
	We get admissibility of necessitation as a lemma for $\Gamma$ empty:
%	\begin{theorem}[Admissibility of Necessitation]{lemma}
		
%		For $  A \in {\sf Prop_0}$, if $\circ\vdash   A$ then $\circ\vdash \Box A$. 
%	\end{threorem}
	As a result:
	\begin{theorem}[Completeness]
		{\sf Jcalc$^{-}$} is complete with respect to the Hilbert style formulation of degree-$1$ intuitionistic $K$ modal logic. 
	\end{theorem}
	
	\subsection{Harmony: Local Soundness and Local Completeness}
	\label{gprinc}
	Before we move on to show (Global) Soundness we provide evidence for the so called ``local soundness" and ``local completeness'' of the $\Box$ connective
	following Gentzen's dictum. The local soundness and completeness for the $\supset$ connective 
	is given elsewhere (e.g. \cite{prawitz10natural}) and in Gentzen's original \cite{gentzen1935untersuchungen}. Gentzen's program can be described with the following two slogans:\begin{itemize} \item[a.] Elim is left-inverse to Intro \item[b.] Intro is right-inverse to Elim\end{itemize}   
	Applied to the $\Box$ connective, the first principle says that introducing a $\Box   A$ (resp. many $\Box A_1, \ldots, \Box A_i$) only to eliminate it (resp. them) directly is redundant. 
	In other words, the elimination rule cannot give you more data than what were inserted in the introduction rule(s)  (``elimination rules are not \textit{too} strong").
	We show first the ``Elim-After-Singleton-Intro" sub-case.
	
	\mbox{\footnotesize
		\begin{mathpar}
			\\
			\inferrule*[right=\large{$\quad\Longrightarrow_{R}\quad$}]{
				\inferrule*{}
				{\inferrule*[]{}{ \inferrule*[]	{\inferrule*[]{}{\PrTri{D} \\ \PrTri{E}}\\\\
							\inferrule*[]{}{\    A\\ \ \qquad \llbracket   A\rrbracket}}{\Box   A }}} \quad
				\inferrule*{}
				{\inferrule*[vdots=1.0em, right=$x$]{ }{  A}\\\\
					\inferrule*[]{}{B}} 	   \qquad 
				\inferrule*{}
				{\inferrule*[vdots=1.0em, right=$s$]{ }{\llbracket   A \rrbracket}\\\\
					\inferrule*[]{}{\llbracket B\rrbracket}} 	
			}
			{\Box B}  \inferrule*[]{
				\inferrule*{}
				{\inferrule*[vdots=1.0em]{}{\PrTri{D} \\\\  A}\\\\
					\inferrule*[]{}{B}}
				\qquad 
				\inferrule*{}
				{\inferrule*[vdots=1.0em]
					{}{\PrTri{E}\\\\\llbracket   A \rrbracket}\\\\
					\inferrule*[]{}{\llbracket B \rrbracket}} 
			}{\Box B}
			
		\end{mathpar}
	}
	The exact same principle applies in the ``Elim-after-Intro''  of   multiple $\Box$s:
	
		\mbox{\footnotesize
			\begin{mathpar}
				\inferrule*[right=$  I_{\Box B} E_{\Box   A}^{x,s}$]{
					\inferrule*{}
					{\inferrule*[]{}{ \inferrule*[]	{\inferrule*[]{}{\PrTri{$D_1$} \\ \PrTri{$E_1$}}\\\\
								\inferrule*[]{}{ \ A_1\\ \ \qquad\ \ \  \llbracket   A_1\rrbracket}}{\Box   A_1 }}}\ldots 
					{\inferrule*[]{}{ \inferrule*[]	{\inferrule*[]{}{\PrTri{$D_i$} \\ \PrTri{$E_1$}}\\\\
								\inferrule*[]{}{\    A_i\\ \ \qquad \llbracket   A_i\rrbracket}}{\Box   A_i }}}
					\quad
					\inferrule*{}
					{\inferrule*[vdots=1.0em, right=$\vec{x}$]{ }{ A_1\dots A_i}\\\\
						\inferrule*[]{}{B}} 	   \qquad 
					\inferrule*{}
					{\inferrule*[vdots=1.0em, right=$\vec{s}$]{ }{\llbracket   A_1 \ldots A_i \rrbracket}\\\\
						\inferrule*[]{}{\llbracket B\rrbracket}} 	
				}
				{\Box B} 
			\end{mathpar}
		}
		$$\Longrightarrow_{R}$$
		\mbox{\footnotesize
			\begin{mathpar}
				\inferrule*[right=$I_{\Box B}$]{
					\inferrule*{}
					{\inferrule*[vdots=1.0em]{}{\PrTri{$D_1$}\ \PrTri{$D_i$} \\\\ A_1\ldots\ldots  \ \  A_i}\\\\
						\inferrule*[]{}{B}}
					\qquad 
					\inferrule*{}
					{\inferrule*[vdots=1.0em]
						{}{\PrTri{$E_1$} \PrTri{$E_i$}\\\\\llbracket   A_1\ldots\ldots A_i\rrbracket}\\\\
						\inferrule*[]{}{\llbracket B \rrbracket}} 
				}{\Box B}
				
			\end{mathpar}
		}
	These equalities are of importance since they dictate (together with the corresponding principles for the $\supset$, $\wedge$ connectives) the proof dynamics of the calculus. 
	The proof term assignment and the corresponding computational ($\beta$-)rules  are directly instructed by these reduction principles. We see that eliminating (using) an introduced $\Box$ 
	corresponds to double substitution in the corresponding judgments. 
	
	Dually, the second principle says eliminating a $\Box A$ , should give enough information to directly reintroduce it (``elimination rules are not \textit{too weak}"). This is an expansion principle.
	
	\mbox{\small
		\begin{mathpar}
			\inferrule*[]{}{ \inferrule*[lab=$\ \mathcal{D}$]{}{\Box   A }}\quad  \Longrightarrow_{E}\quad
			\inferrule*[Right=$I_{\Box A}E^{x,s}_{\Box  A}$]{
				\inferrule*{}
				{\inferrule*[]{}{  }\\\\ \quad\inferrule*[]{}{ \inferrule*[lab=$\ \mathcal{D}$]{}{\Box   A }}\\
				} \qquad
				\inferrule*{}
				{\inferrule*[right=$x$]{ }{  A}}\\
				\inferrule*{}
				{\inferrule*[right=$s$]{ }{\llbracket A\rrbracket}
				} 	
			}
			{\Box   A} 
		\end{mathpar}}
		\subsection{(Global) Soundness}
		\label{seqcalc}
		Soundness is shown by proof theoretic techniques. Standardly, we add the bottom type ($\bot$) to {\sf Jcalc$^{-}$} together with its elimination rule and show  that the system is consistent ($\not\vdash \bot$) by   devising a sequent calculus  and showing admissibility of cut. We 
		only present the calculus here and collect the theorems towards consistency  in the Appendix. 
		
		In the following we use $\Gamma\Rightarrow   A$ (where $\Gamma,  A \in {\sf Prop_0}\cup{\sf Prop_1})$  to denote 
		sequents modulo $\Gamma$ permutations where $\Gamma$ is a multiset of ${\sf Prop}$ (no labels)  and $\Delta \Rightarrow\sf \llbracket   A \rrbracket$ for sequents corresponding to $\llbracket \sf judgments \rrbracket$ of the calculus modulo $\Delta$ permutations (with $\Delta$ (unlabeled) multiset of ${\sf \llbracket Prop_0 \rrbracket}$). The multiset/ modulo permutation approach is instructed by standard structural properties. 
		All properties are stated formally and proved in the Appendix. 
		
		The  $\llbracket\Gamma\rrbracket \Rightarrow \llbracket A \rrbracket$ relation  is defined directly from  $\vdash$:
		\begin{mdframed}[nobreak=true,frametitle={\footnotesize Sequent Calculus ($\llbracket {\sf Prop_0} \rrbracket$)}]
			$$\begin{array}{l r}
			{\llbracket\Gamma\rrbracket} \Rightarrow \llbracket A\rrbracket:= & \exists \Gamma^{\prime}\in \pi(\llbracket\Gamma\rrbracket)\ \text{s.t} \   
			\Gamma^{\prime}\vdash \llbracket A \rrbracket \end{array}$$
			where $\pi(\llbracket\Gamma\rrbracket)$ is the collection of  permutations of $\llbracket\Gamma\rrbracket$.
		\end{mdframed} 
		
		
		\begin{mdframed}[nobreak=true,frametitle={\footnotesize Sequent Calculus ({\sf Prop})}]
			\mbox{\small
				\begin{mathpar}
					\inferrule*[right=$Id$] { }{\Gamma, A  \Rightarrow A }
					
					\inferrule*[right=$\supset_L$] {{\Gamma, A\supset B, B \Rightarrow  C }\\ {\Gamma, A\supset B \Rightarrow A}} {\Gamma, A\supset B \Rightarrow  C}
					\and
					\inferrule*[right=$\supset_R$] {\Gamma, A \Rightarrow  B} {\Gamma \Rightarrow A\supset B}
					\and
					\inferrule*[right=$\bot_L$] { } {\Gamma, \bot \Rightarrow A}
					\and
					\inferrule*[right=$\Box_{LR}$] {{\Box\Gamma,\Gamma\Rightarrow A}\\{\llbracket\Gamma\rrbracket\Rightarrow \llbracket A \rrbracket }}{\Box\Gamma\Rightarrow \Box A}
					%\inferrule*[right=$\supset$E] {{\Turn {\Gamma} { A\supset  B}}\\{\Turn {\Gamma} { A}}} {\Turn {\Gamma} {   B}}
					%\and
					%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
				\end{mathpar}}
				%Where the  rule $\Box_{LR}$corresponds to $\Box_{IE}$ and relates the two kinds of sequents 
			\end{mdframed}
			
			Standardly, we  extend the system with the ${\sf Cut}$ rule and we  obtain the extended system $\Gamma \Rightarrow^{+} A:= \Gamma\Rightarrow A + {\sf Cut}$. 
			We show Completeness of $\Rightarrow^{+}$ with respect to Natural Deduction and  Admissibility of Cut that leads to the consistency result
			%\begin{theorem}[Admissibility of Cut]
			%$\Gamma \Rightarrow^{+}A$ implies $\Gamma\Rightarrow A$
			%\end{theorem}
			%Which together with the following theorems:
			%\begin{theorem}[Completeness of $\Rightarrow^{+}$ with respect to Natural Deduction]
			%If  $\Gamma\vdash A$ then $\Gamma \Rightarrow^{+}A$
			%\end{theorem}
			%Which together with the proposition: 
			%\begin{proposition}
			%$\centernot{\Rightarrow^{+}}\bot$
			%\end{proposition}
			\begin{theorem}[Consistency of {\sf Jcalc$^{-}$}]{theorem}{firstcon}
				$\centernot{\vdash}\bot$
			\end{theorem}
			
			
			
			%\begin{mathpar}
			%\inferrule*[right=K]  {  A\supset  B\supset A \in [Prop]_{i>0}}    {{\Delta} \vdash  {{\sf K}[ A, B]:  A\supset B\supset A}}
			%\and
			%\inferrule*[right=S]  { A\supset B\supset C \in [Prop]_{i>0}}    {{\Delta} \vdash  {{\sf S}[ A, B, C]: ( A\supset B\supset C)\supset( A\supset B)\supset( A\supset C)}}
			
			%\and
			%\inferrule*[right= App] {{\Turn {\Gamma, x: A} {M: B}}\\{\Turn {\Gamma} {\sf wf_{i>0}} }} {\Turn {\Gamma} {\lambda  x: A . \   M :  A\supset  B}}
			%\and
			%\inferrule*[right=]{{\Turn {\vec{v}:G} {t: A}}\\{\Turn {\vec{v'}:[G]} {t':[ A]} }} {\Turn {\vec{x}:\Box G}  let\  { \xshlongvec[1] {link(v,v')=x}\  {\sf in} \  link(t,t')}:\Box  A}
			%\end{mathpar}
			
			%Finally, we have the rule that relates judgments of truth to judgments of validity explained in the beginning of this section.
			\section{Order theoretic semantics}
			This chapter started by introducing 
			mappings between deductive systems and 
			motivating the reading of necessity as ``double-proof under a map''.
			As a result, it is unsuprising the the calculus is amenable to order theoretic sematics.
			We present them in this section.

			In order to progress we first define the notion of a \vocab{semi-Heyting  Algebra(semi-HA)}. 
			To define \vocab{semi-HA} we need the notion of a \emph{(meet) semi-lattice}.
			  
			
			\begin{mdframed}
			\textbf{Definition:}
			A \textit{(meet) semi-lattice} is a non-empty \emph{partial order} (i.e. reflexive, antisymmetric and transitive) 
			with finite meets.
			\end{mdframed}
			In addition, we define \emph{meet semi-lattice} as follows: 
			\begin{mdframed}
			\textbf{Definition:}
			A \textit{bounded (meet) semi-lattice} $(L,\le)$ is a (meet) semi-lattice that additionally has 
			a greatest element $1$, which satisfies
			
			$x \le 1$ for every $x$ in $L$
			\end{mdframed}
			Finally, we can define \emph{semi-HA}:
			
			\begin{mdframed}
			\textbf{Definition:}
			A \textit{semi-HA} is a bounded (meet) semi-lattice $(L,\le, 1)$ 
			s.t. for every $a,b\in L$ there exists an \textit{exponential} 
			(we name it $a\supset b$) 
			with the properties: 
			\begin{enumerate}
			\item $a\wedge a\supset b\le b $
			\item $x$ is the greatest such element
			\end{enumerate}
			\end{mdframed}
			\subsubsection{Axiomatization of semi-HAs}
			We can axiomatize the meet (i.e. greatest lower bound)($\wedge$) of $\phi,\psi$ for any  lower bound $\chi$.
			\begin{mdframed}
			\begin{mathpar}
			  \infer{\phi \conj \psi \leq \phi}{
				}
			  \and
			  \infer{\phi \conj \psi \leq \psi}{
				} 
			\end{mathpar}
			\begin{equation*}
			  \infer{\chi \leq \phi \conj \psi}{
				\chi \leq \phi & \chi \leq \psi} 
			\end{equation*}
			\end{mdframed}
			
			We can axiomatize the existence of a greatest element as follows:
			\begin{mdframed}
			\begin{equation*}
			  \infer{\chi \leq 1}{
				} 
			\end{equation*}
			which says that $1$ is the greatest element.
			\end{mdframed}
			Finally, to axiomatize \emph{semi-HAs} we require the existence of exponentials for every $\phi$, $\psi$ as follows:
			
			\begin{mdframed}
			\begin{mathpar}
			  \infer{\phi \wedge  (\phi\supset \psi)\leq\psi}{
				} 
				\and
				\infer{\chi\leq\phi\supset\psi}{\phi\wedge\chi\leq\psi}
			\end{mathpar}
			\end{mdframed}
			
			In addition, given two \emph{semi-HAs}, we are interested in order preserving 
			functions (functors) $F$ that also preserve products and exponentials: 
			\begin{mdframed}
				\textbf{Definition}
			A function $F$ between two (semi)-HAs ($HA_1$, $HA_2$) is order preserving
			and commutes with products and exponentials \emph{iff}
				\begin{enumerate}
				\item $\phi\le_{1}\psi\Rightarrow F\phi \le_{2} F\psi$
				\item{$F(\phi \wedge_{1}\psi) = F(\phi)\wedge_{2}(F(\psi))$} 
				\item{$F(\phi\supset_{1}\psi}) = F(\phi) \supset_{2} F(\psi)$}
				\end{enumerate}
			\end{mdframed}
			
			For the order theoretic models of  Jcalc $^{-}$ the following structures (triplets) 
			are of interest. We define a $J$-triplet as follows:
			\begin{mdframed}
				\textbf{Definition}
			A \emph{$J$-triplet} is 
				
			\begin{enumerate}
			\item A semi-Hayting algebra $HA$
			\item A partial order $J$
			\item An order preserving function $F$ from $HA$ to $J$ s.t.
			\begin{enumerate}
				\item The image $F(HA)$ forms a semi-Heyting Algebra
				\item $F$ preserves products and exponentials
			\end{enumerate}
			\end{enumerate}
		\end{mdframed}

			Given a $J$-triplet we define the induced pair algebra
			$\langle HA, F(HA)\rangle$
			and name it $\Box^{F}HA$ as follows:
			\begin{mdframed}
				\textbf{Definition} Given a $J$-triplet we define the induced 
				$\Box^{F}HA$ as follows:
				
			\begin{enumerate}
				\item Elements are pairs $\langle A, FA\rangle$ (name them $\Box^{F}A$) where $A\in HA$ and $FA$ its image
				\item For every two elements  $\Box^{F}A$, $\Box^{F}B$:
				$$\Box^{F}A \le_{\Box^{F}}B \Box^{F}B \text{iff} A\le{HA}B \text{and} FA\le_J FB $$^{\footnote
				Actually in a $J$-triplet case (
					actuallly in a $ A\le{HA}B$ implies $FA\le_J FB$ but the definition of pair algebras
					of proof systems can be generalized to weaker scenarios as we will sketch in the next section
				)}
			\end{enumerate}
		\end{mdframed}
		\begin{mdframed}
			\begin{theorem}\label{thm:PairAlgebra}
			$\Gamma\vdash_{IPL} \phi \true$ iff for any \vocab{Heyting Algebra} $H$ we have $\Gamma^+\leq\phi^{*}$ where $*$ is  defined as the lifting of any map of $\prop$s to elements of $H$ and $(+)$ is defined inductively on the length of $\Gamma$ as follows
			\begin{alignat*}{2}
			  nil^+  &&\quad = & \quad\top\\
			  (\Gamma,\phi)^+&&\quad = &\quad
			  \Gamma^+\wedge\phi* \
			\end{alignat*}
			\end{theorem}
			\end{mdframed}



\chapter{The computational side of Jcalc $^{-}$}
			In this section we add proof terms to represent natural deduction constructions. The  meaning of these terms emerges naturally from Gentzen's principles that give reduction (computational $\beta$-rules) and expansion (i.e. extensionality $\eta$-rules) equalities for the each construct. We focus on the new constructs of the calculus that emerge from the judgmental interpretation of the $\Box$ connective as explained in 
			section \ref{lsjcalc}.
			
			There will be no computational (reduction) rules on  provability terms. 
			This conforms with our reading of these terms  as \textit{references} to proof constructs of an \textit{abstracted} theory $J$ that can be realized 
			differently for a concrete $J$.  
			%This is, we posit, the logical basis for \textit{dynamic linking} under separate compilation. The linker from a language $I$ to any host language $J$ (that satisfies certain specifications) creates residuals dynamically but is not concerned about the actual execution of such residuals. Execution of such residuals happens at a next phase when the references are dereferenced to code of the host and is not observed by the calculus.\footnote{ Such approach, also conforms with justification logic principles. Justifications are static, purely syntactical constructs that are not further analyzed.} 
			\subsection{Proof term assignment}
			\label{basicpras}
			The following rules and their correspondence with natural deduction  constructs (\ref{jots}) should be obvious to the reader familiar with the simply typed  $\lambda$-calculus and basic justification logic.
			We do not repeat here the corresponding $\beta, \eta$ equality rules since they are standard.
			\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Truth  $\Gamma, A,B \in {\sf Prop_0}$  and $M := x_i\  |\  <> \ |\ \lambda x:A.\ M\  |\  (M M) $}]
				\label{jot}
				\mbox{\small
					\begin{mathpar}
						\inferrule*[right=$\Gamma_0$-Refl] {x: A \in \Gamma}{\Turn {\Gamma} { x:A}}
						\and
						\inferrule*[right=$\top_0$I] { }{\Turn {\Gamma} { <>:\top}}
						\and
						\inferrule*[right=$\supset_0$I] {{\Turn {\Gamma, x: A} { M:B}}} {\Turn {\Gamma} { \lambda x:A.\  M:  A\supset  B}}
						\and
						\inferrule*[right=$\supset_0$E] {{\Turn {\Gamma} { M:A\supset  B}}\\{\Turn {\Gamma} {M^{\prime}: A}}} {\Turn {\Gamma} { (MM^{'}):  B}}
						\and
						\inferrule*[right=]{}{+\  \beta\eta \text{\ equalities for \ } \top,\supset}
						%\and
						%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
					\end{mathpar}}
				\end{mdframed}
				
				For  judgments of ${\sf \llbracket Prop_0\rrbracket}$, we assume a countable set of constant names and demand that every combinatorial
				axiom of intuitionistic logic has  a witness under the interpretation 
				$\llbracket\bullet\rrbracket$. This is what justification logicians call ``axiomatically appropriate constant specification''.
				As usual we demand reflection of contexts in $J$
				and preservation of modus ponens -- closedness under some notion of application (which we denote as $*$).
				
				%\begin{mathpar}
				%\inferrule*[right=$CS$] {{\Turn {\Delta} {\sf \llbracket wf \rrbracket}}\\ {C_i:\llbracket  A\rrbracket \in CS}} {\Delta\vdash_{CS}C_i:\llbracket  A\rrbracket}
				%\end{mathpar}
				
				\begin{mdframed}[nobreak=true,frametitle={\footnotesize Judgments on Validity  $\Delta\in {\sf \llbracket Prop_0\rrbracket}$  and ${\sf J} :=  s_i\ |\ C_i\  | \ {\sf J}*{\sf J} $}]
					\label{justf}
					\mbox{\small
						\begin{mathpar}
							\inferrule*[right=$\Delta$-Refl] {  {s:\llbracket  A\rrbracket \in \Delta}}{\Turn {\Delta} {s:\llbracket  A\rrbracket}}
							\and
							\inferrule*[right=  Ax$_1$]{ }   {\Delta\vdash C_{\top}: \llbracket  \top\rrbracket}
							\and
							\inferrule*[right=  Ax$_2$]{{  A, B \in {\sf Prop_0} }}   {\Delta\vdash C_{K^{A,B}}: \llbracket   A \supset (B \supset   A)\rrbracket }
							\and
							\inferrule*[right=  Ax$_3$]{ {  A,B, C \in {\sf Prop_0}}}{\Delta\vdash C_{S^{A,B,C}}:\llbracket   A\supset (B \supset C) \supset ((  A\supset B) \supset (  A \supset C))\rrbracket}
							\and
							\inferrule*[right=App] {{\Turn {\Delta} { {\sf J}: \llbracket  A \supset  B \rrbracket}}\\ {\Turn{\Delta} {{\sf J'}:\llbracket  A \rrbracket}}}{\Turn {\Delta} { {\sf J*J^\prime}:\llbracket  B\rrbracket}}
							
							
						\end{mathpar}
					}
				\end{mdframed}
				If  $J$ is a proof calculus and $\llbracket\bullet \rrbracket_J$ is  an interpretation such that the specifications above  
				are realized, then $J$ can witness intuitionistic provability. This can be shown by the proof relevant version of the lifting  lemma
				that states:
				\begin{lemma}[$\llbracket\bullet\rrbracket$Lifting Lemma]
					\label{bracklift}
					Given  $\Gamma,  A \in {\sf Prop_0}$ s.t. and a term $M$ s.t. $\Gamma\vdash  M: A $ then there exists ${\sf J}$ s.t  $\llbracket \Gamma\rrbracket \vdash {\sf J}:\llbracket   A \rrbracket$. 
				\end{lemma}
				
				
				
				
				\subsubsection{Proof term assignment and Gentzen Equalities for $\Box$ Judgments}
				Before we proceed, we will give a small primer of \textit{let}-bindings as used in modern programming languages to provide for some intuition on how such terms work. 
				Let us assume a rudimentary programming language that supports some basic types, say integers (${\sf int}$), as well as pairs of such types. Moreover, let us define a datatype 
				$\sf{Point}$ as a pair of ${\sf int}$ i.e. as $\sf {(int,int)}$ 
				In  a language with \textit{let}-bindings one can define a simple function that takes a ${\sf Point}$ and ``shifts'' it by adding $1$ to each of its $x$ and $y$ coordinates as follows:
				\begin{lstlisting}
				def shift (p:Point) = 
				let  (x,y) be p
				in
				(x+1,y+1)
				\end{lstlisting}
				If we call this function on the point ${\texttt{(2,3)}}$, then the computation ${\texttt{let (x,y) be (2,3) in (x+1,y+1)}}$ is invoked. This expression reduces following the \textit{let} reduction rule
				(i.e. pattern matching and substitution) to $\texttt{(2+1,3+1)}$; and as a result we obtain the value $\texttt{(3,4)}$.  As we will see, {\textit{let}} bindings -- with appropriate typing restrictions for our system -- 
				are used in the assignment of proof terms for the $\Box_{IE}$ rule. Moreover, the reduction principle for such terms ($\beta$-rule) -- obtained following Gentzen's equalities for the $\Box$ connective --  
				is exactly the one that we just informally described. 
				
				We can now move forward with the  proof term assignment for the $\Box_{IE}$ rule.  We show first the sub-cases for $\Gamma'$ empty (pure $\Box_I$)  and $\Gamma'$ singleton and explain the computational significance 
				utilizing Gentzen's principles appropriated for the $\Box$ connective. We are  directly translating proof tree equalities from \ref{gprinc} to proof term equalities. 
				We generalize for arbitrary $\Gamma'$ in the following subsection. We have, respectively, the following instances:
				
				\begin{mathpar}
					\inferrule*[]{ {\Gamma\in{\sf Prop_1}}\\{\Turn {\circ} { M:B}}\\{\Turn {\dagger} {{\sf J}:\llbracket  B\rrbracket} }} {\Turn {\Gamma} {  M\& {\sf J}:\Box  B}}
					\and
					\inferrule*[]{{ \Turn {\Gamma}{N:\Box  A}}\\{\Turn {x:A} { M:B}}\\{\Turn {s:\llbracket A \rrbracket} {{\sf J}:\llbracket  B\rrbracket} }} {\Turn {\Gamma} {{\sf let} \ (x\& s \ \ {\sf be\ } N) \ {\sf in}\  (M\& {\sf J}):\Box  B}}
				\end{mathpar}
				
				\subsubsection{Gentzen's Equalities for  ($\Box$ terms)}
				Gentzen's reduction and expansion principles give computational meaning (dynamics) and an extensionality principle for linking terms. We omit naming the empty contexts for economy.
				
				\mbox{\small
					\begin{mathpar}
						\inferrule*[Right=$I_{\Box B} E_{\Box A}^{x,s}$]{
							{\inferrule*[Left=$\Box_I$]{{\Gamma\in {\sf Prop_1}}\\ \vdash M:A\\ \vdash {\sf j}:\llbracket A \rrbracket}{\Gamma\vdash M \& {\sf j}:\Box A}}\\{x:A\vdash M':B }\\ {s:\llbracket A\rrbracket \vdash {\sf j'}:\llbracket B \rrbracket}}
						{\Gamma\vdash {\sf let} \ \ (x\& s)\ \ {\sf be}\ \   (M\&  {\sf J}) \ \ {\sf in}\ \  { (M^\prime \& {\sf J^\prime})}:\Box B }
					\end{mathpar}
				}$$\Longrightarrow_{R}$$
				\mbox{\small
					\begin{mathpar}
						\inferrule*[Right=$I_{\Box B}$]{\Gamma \in {\sf Prop_1}\\ \vdash M'[M/x]:B \\ \vdash {\sf J^{\prime}}[{\sf J}/s]:\llbracket B \rrbracket}{\Gamma\vdash { M^{\prime}[M/x]\& {\sf J^{\prime}}[{\sf j}/s]}:\Box B} 
					\end{mathpar}
				}
				Where the expressions $M^\prime[M/x]$ and ${\sf J^\prime[J/s]}$ denote capture avoiding substitution, reflecting proof compositionality of the two calculi.
				
				Following the expansion principle we obtain:
				{\small
					$$\begin{array}{c}
					\Gamma\vdash M:\Box   A
					\end{array} \ \Longrightarrow_{E}$$}
				\mbox{\small
					\begin{mathpar}
						\inferrule*[right=$I_{\Box A}E^{{x},{s}}_{\Box A}$]{{ \Turn {\Gamma}{M:\Box  A}}\\{\Turn {x:A} { x:A}}\\{\Turn {s:\llbracket A \rrbracket} {s:\llbracket  A\rrbracket} }} {\Turn {\Gamma} {{\sf let} \ (x\& s \ {\sf be \ } M) \ {\sf in}\  (x\& s):\Box  A}}
					\end{mathpar}}
					
					That gives an $\eta$-equality as follows:
					{\small
						$$M:\Box A =_{\eta}\ \ {\sf let} \ \ (x \& s\  {\sf be} \ M)\ \ {\sf in}\ \  { (x \& s)}:\Box A$$
					}
					The $\eta$ equality demands that every $M:\Box A$ should be reducible to a form $M'\& {\sf J^{\prime}}$.  
					\subsubsection{Proof term assignment for the $\Box$ rule (Generically)}
					After understanding the computational meaning of let expressions in the $\Box_{IE}$ rule 
					we can now give  proof term assignment  for the rule in the general case(i.e. for $\Gamma'$ of arbitrary length). 
					We define a helper syntactic construct --${\sf let}^{*}\ldots {\ \sf in\ }$-- as syntactic sugar for iterative  let bindings based on the structure  of contexts.
					The ${\sf let}^{*}$ macro takes four arguments: a context $\Gamma\in {\sf Prop_0}$, a  context $\Delta\in{\sf \llbracket Prop_1\rrbracket}$,  
					a possibly empty ($[\ ]$) list of terms  $Ns:=N_1,\ldots,  N_i$ - all three of the same length - and a term $M$. It is defined as follows for the empty and non-empty cases:
					%\footnote{Let us stretch here that when we speak about the structure of $\Gamma$ we imply (given the construction of $\Gamma\vdash{\sf wf}$) a treatment of contexts as lists where $\bullet$ stands for the empty list, singleton $x:A$ for $x:A + \bullet$ and contexts written in the form  $\Gamma,x:A$ for $x:A + \Gamma$ where $\Gamma$ is a list. I.e. contexts are lists but written down inversely with the head in the rightmost position. We treat the list of terms $Ns$ similarly for uniformity}  
					
					{\small
						$$\begin{array}{ll}
						\nonumber {\sf let}^{*}\ (\circ;\ \dagger;\  [\ ]) {\ \sf in\ }  M:= M \  &\\
						\nonumber {\sf let}^{*}\ (x_1:A_1,\ldots, x_i:A_i\ ;\  s_1: \phi_1, \ldots, s_i:\phi_i;\  N_1,\ldots,  N_i) {\ \sf in\ } M:= \  & \\
						{\sf let} \ \{(x_1 \& s_1)\  {\sf be}\  N_1,\ldots,  (x_i \& s_i)\  {\sf be}\  N_i\}\ {\sf in}\  M &\\
						\end{array}$$}
					Using this syntactic definition the rule $\Box_{IE}$ rule  can be written compactly:
					
					\begin{mdframed}[nobreak=true,frametitle= \footnotesize{$\Box_{IE}\ \text{ With}\ \Gamma\in {\sf  Prop_1}\text{,}\  \Gamma^{\prime}\in {\sf Prop_0}\text{,{\ \sf length}}(\Gamma)=i\text{,\ }Ns:=N_1 ...\  N_i\text{,}\ 1\le k\le i$} ]% $\Gamma^\prime\in {\sf Prop_0}$ ]
						\mbox{\small
							\begin{mathpar}
								\inferrule*[right=$I_{\Box B}E^{\vec{x},\vec{s}}_{\Box A_1\ldots \Box A_i}$] %{}
								{{\forall A_k \in \Gamma^\prime . \   \Gamma \vdash N_k:\Box A_k}\\
									{\Turn {\Gamma^\prime} {M:B}}\\{\Turn {\llbracket\Gamma^\prime\rrbracket} {{\sf J}:\llbracket B \rrbracket} }} 
								{\Turn {\Gamma} {{\sf let^{*}}\ (\Gamma^\prime, \llbracket\Gamma^\prime\rrbracket, Ns) \ {\sf in}  \ ( M\& {\sf J}):\Box B}}
							\end{mathpar}
						}
					\end{mdframed}
					It is obvious that all previously mentioned cases are captured with this formulation. The rule of $\beta$-equality can be given  for multi-let bindings directly from Gentzen's reduction principle (\ref{gprinc}) generalized for 
					the multiple intro case shown in the appendix (\ref{redmult}). 
					{\small
						$$\begin{array}{ll}
						{\sf let} \{(x_1 \& s_1) {\ \sf be\ } (M_1\& {\sf J_1}),\ldots,  (x_i \& s_i) {\ {\sf be}\ } (M_i\& {\sf J_i})\}\ {\sf in}\  (M \&  {\sf J})& =_{\beta} \\
						{  M[M_1/x_1, \ldots,  M_i/x_i] \& {\sf J}[{\sf J_1}/s_1,\ldots, {\sf J_i}/s_i]}
						\end{array}$$}
					\subsection{Strong Normalization and small-step semantics}
					In the appendix (\ref{norm}) we provide a proof of normalization for  natural deduction (via cut elimination). 
					This is ``essentially" a strong normalization result for the proof term system also. In general we have shown the congruence obtained from $=_{\beta\eta}$ rules gives a  consistent equational system.
					Nevertheless, we leave this for an extended version of this paper. Instead, we sketch briefly a weaker result: normalization under a  deterministic,``call-by-value" reduction strategy for $\beta$-rules.
					This   gives
					an idea of how the system computes  and we can use it in the applications in the next section. As usual we characterize a subset of the closed terms as values and we provide rules for the reduction of the non-value closed terms.
					Note that for the constants of validity and their applicative closure we do not observe reduction properties but treat them as values -- again conforming with the idea of $J$ (and its reduction principles) being ``black boxed''.
					\begin{mdframed}[nobreak=true,frametitle={\footnotesize Small step, call-by-value reduction $\rightarrow$}]
						\begin{mathpar}
							\inferrule*[] { }{\lambda x. M {\ \sf  value}}
							\and
							\inferrule*[] { } {C_i {\ \sf \ value}}
							\and
							\inferrule*[] {{\sf J_1} {\ \sf value} \\ {{\sf J_2} {\ \sf value}} }  {{\sf J_1*J_2} {\ \sf value}}
							\and
							\inferrule*[] {M\  {\sf value} \\ {{\sf J}\  {\sf value}} }  {M \&{\sf J} {\sf \ value}}
							\and
							\inferrule*[] {M \rightarrow M^\prime}  {M \&{\sf J}\rightarrow M^\prime \& {\sf J}}
							\and
							\inferrule*[] {{N_1 \ {\sf value}\  \ldots\text{ \ }  N_{k-1} \ {\sf value}}\\{N_k\rightarrow N_k^{\prime}}}  {{\sf let} \{(x_1 \& s_1) {\ \sf {be}\ } N_1,\ldots,
								\  (x_{k} \& s_{k}) {\ \sf {be } \ } N_k{\text{,}} \ldots\}    {\ \sf in}\  M \rightarrow \\
								{\sf let} \{(x_1 \& s_1) {\ \sf {be}\ } N_1,\ldots,
								\  (x_{k} \& s_{k}) {\ \sf {be } \ } N_k^{\prime}{\text{,}} \ldots\}    {\ \sf in}\  M }
							\and
							\inferrule*[] {M_1 \& {\sf J_1 \ value\ } \ldots\text{\ }  M_i \& {\sf J_i \ value}}  {{\sf let} \{(x_1 \& s_1) {\ \sf be\ } (M_1\& {\sf J_1}),\ldots,  (x_i \& s_i) {\ {\sf be}\ }
								(M_i\& {\sf J_i})\}\ {\sf in}\  (M \&  {\sf J})\rightarrow \\
								{  M[M_1/x_1, \ldots,  M_i/x_i] \& {\sf J}[{\sf J_1}/s_1,\ldots, {\sf J_i}/s_i]}}
							\and
							\inferrule*[] {M \rightarrow M^{\prime}}  {(MN) \rightarrow (M^\prime N)}
							\and
							\inferrule*[] {N \rightarrow N^{\prime} }  {((\lambda x. M)N) \rightarrow ((\lambda x. M)N^\prime) }
							\and
							\inferrule*[] {N {\ \sf value}}  {((\lambda x. M)N) \rightarrow [N/x]M }
							%\and
							%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
						\end{mathpar}
					\end{mdframed}
					Using the reducibility candidates proof method \cite{citeulike:993095}) we show:
					\begin{theorem}[Termination Under Small Step Reduction]
						With $\rightarrow^{*}$ being the reflexive transitive closure of $\rightarrow$: for every closed term $M$ and $A \in {\sf Prop}$ if $\vdash M:A$ then there 
						exists $N \ {\sf value}$ s.t. $\vdash N:A$ and  $M\rightarrow^{*} N$.
					\end{theorem}
					
					\section{A programming language view: Dynamic Linking and separate compilation}
					\label{dlinker}
					Our type system can be related to programming language design when considering \textit{Foreign Function Interfaces}. This is a typical scenario in which a language $I$ interfaces another language $J$ which is  essentially ``black boxed''.
					For example, {\sf OCaml} code  might call {\sf C} code to perform certain computations. 
					In such cases $I$ is a client and $J$ is a host that provides implementations for an interface utilized by the client.
					Through software development,  often the implementations of such an interface might change (i.e. a new version of the host language, or more dramatically, a complete switch of host language). 
					We want a language design that satisfies
					two  interconnected 
					properties. First, \textit{separate compilation} i.e. when implementations change we do not have to recompile client code and, yet, 
					secondly, \textit{dynamic linking} we want the client code to be linked dynamically to its new 
					``meaning''.
					
					We will assume that both languages are  functional and based on the lambda calculus. I.e. our interpretation function should have the property $\llbracket A\supset B\rrbracket_J$=
					$\llbracket A\rrbracket_J \llbracket\supset\rrbracket_J \llbracket B\rrbracket_J$ where  $\llbracket\supset\rrbracket_J$ is the implication type constructor in $J$.
					The specifics of the host  $J$ and the concrete implementations are unknown to $I$ but during the linker construction we assume that both languages share  some  basic types
					for otherwise  typed ``communication'' of the two languages would be impossible. 
					Simplifying,  we consider that the only  shared type is  (${\sf int}$), i.e. the linker construction assumes  
					$\bar{n}:\llbracket \sf int \rrbracket$ for every integer $n:{\sf int}$. 
					Let us now assume source code in $I$ that
					is  interfacing   a simple data structure, say an  integer stack,  with the following signature ${\sf \Sigma}$:
					\begin{lstlisting} 
					using type intstack
					empty: intstack, push: int -> intstack -> intstack,
					pop: intstack -> int
					\end{lstlisting}
					
					
					And let us consider a simple program in $I$ that is using the signature say, 
					$${\texttt{pop(push (1+1) empty):int}}$$
					This program involves two kinds of computations: a redex $(1+1)$ that can be reduced using the internal semantics of the language $1+1\rightsquigarrow_{I} 2$ and  
					the signature calls ${{\texttt{pop (push 2 empty)}}}$ 
					that are to be performed
					externally  in whichever host language implements them. 
					We treat  dynamic linkers as ``term re-writers'' that map  a computation to its meaning(s) based on different implementations.
					In the following we consider ${\sf \Sigma}$ to be the signature of the interface. Here are the steps towards the linker construction.
					
					\begin{enumerate}
						\item Reduce the source code based on the operational semantics of $I$ until it doesn't have a redex:
						\small{${\sf \Sigma}; \bullet\mathtt{\vdash_{} pop (push \ (1+1) \ Empty)\rightsquigarrow pop (push \ 2 \ Empty) :int}$}
						\item Contextualize the use of the signature at the final term in step $1$:{\small
							\begin{flalign*}
							& \mathtt{{\sf \Sigma}; x_1:intstack,  x_2:int\rightarrow intstack\rightarrow intstack, x_3:intstack\rightarrow int \vdash x_3 (x_2 \ 2\  x_1):int} &
							\end{flalign*}}
						\item Rewrite the previous judgment assuming (abstract) implementations for the corresponding missing elements
						using the ``known'' specification for the shared elements.
						{\small
							\begin{flalign*}
							& \mathtt{ s_1:\llbracket instack \rrbracket,  s_2:\llbracket int \rightarrow intstack\rightarrow intstack\rrbracket, 
								s_3:\llbracket intstack\rightarrow int \rrbracket\vdash s_3*(s_2* \bar{2}*s_1):\llbracket int\rrbracket}&
							\end{flalign*}}
						\item Combine the two previous judgments using the $\Box_{IE}$ rule.
						{\small
							\begin{flalign*}
							& {\sf \Sigma};\mathtt{x_1^{\prime}:\Box intstack ,x_2^{\prime}:\Box(int\rightarrow intstack\rightarrow intstack), x_3^{\prime}: \Box  (intstack\rightarrow int)\vdash} & \\
							& \mathtt{ let\{ x_1\& s_1 {\ \sf be \ } x_1^{\prime},\ x_2\& s_2 {\ \sf be \ } x_2^{\prime}, \  x_3\& s_3 {\ \sf be \ } x_3^{\prime} \}\  in}\   \mathtt{(x_3 (x_2\ 2 \ x_1)\ \& \ s_3*(s_2* \bar{2}*s_1)):\Box int} &
							\end{flalign*}}
						\item Using $\lambda$-abstraction three times we obtain the dynamic linker:
						{\small
							\begin{flalign*}
							& {\sf \Sigma};\circ\vdash \\
							& \mathtt{linker} = \mathtt{\lambda x_1^{\prime}.\  \lambda x_2^{\prime}}. \lambda x_3^{\prime}. \\
							& \mathtt{let \{ x_1\& s_1 {\ \sf be \ }x_1^{\prime},\ x_2\& s_2 {\ \sf be \ }  x_2^{\prime},\ x_3\& s_3 {\ {\sf be} \ } x_3^{\prime}\}\  in} \mathtt{(x_3(x_2\ 2 \ x_1)\ \&\  s_3*(s_2*\bar{2}*s_1))} &\\
							&\mathtt{:\Box(instack)\rightarrow \Box(int\rightarrow intstack\rightarrow intstack) \rightarrow \Box (intstack\rightarrow int) \rightarrow \Box int}
							\end{flalign*}}
					\end{enumerate}
					Let us see how it can be used in the presence of different implementations:
					\begin{enumerate}
						\item Suppose the developer  responsible for the implementation of the interface is providing an  array based implementation for the stack  in  some language $J$ 
						i.e. we get references to typechecked code fragments of $J$ as follows{\footnote{We have changed the return type of $\mathtt{pop}$ to avoid products. This is just for economy and products can easily be handled.}}:
						{\small
							\begin{flalign*}
							& \mathtt{create():intarray},\  \mathtt{add\_array:int_J \rightarrow_J intarray \rightarrow_J intarray } & \\
							& \mathtt{pop\_array:intarray \rightarrow_J int } &
							\end{flalign*}}
						\item  A unification algorithm check is performed to verify the conformance of the implementations to the signature taking into account 
						fixed type sharing equalities ($\llbracket {\sf int} \rrbracket = {\sf int_J}$). In our case it produces: $$\llbracket\rightarrow\rrbracket = \mathtt{\rightarrow_J}, \llbracket {\sf intstack} \rrbracket= {\sf intarray}$$
						\item
						We thus obtain typechecked links using the $\Box_I$ rule. For example:
						
						\mbox{\small
							\begin{mathpar}
								\inferrule*[]{{\Turn {{\sf \Sigma};\circ} { \mathtt{push: int \rightarrow intstack \rightarrow intstack }}}\\{\Turn {\bullet} {\mathtt{add\_array:\llbracket int \rightarrow intstack \rightarrow intstack\rrbracket  }} }} {\Turn {{\sf \Sigma};\circ} {  \mathtt{ push\  \& {\ \sf add\_array}:\Box (int \rightarrow intstack \rightarrow intstack)}}}
							\end{mathpar}
						}
						And analogously:
						
						\mbox{\small
							\begin{mathpar}
								\inferrule*[]{} {{\sf \Sigma}; \circ\vdash {  \mathtt{ pop\  \& \ {\sf pop\_array}:\Box (intstack\rightarrow int)}}}
								\and
								\inferrule*[]{} {{\sf \Sigma}; \circ\vdash {  \mathtt{ empty\  \& {\sf create()}:\Box intstack}}}	
							\end{mathpar}
						}
						\item Finally we can compute the next step in the computation for the expression  applying the linker to the obtained pairings:{\small\begin{flalign*}
							&{\sf \Sigma}; \bullet\mathtt{\vdash_{}(linker\   (empty\  \& \ create()) \ (push\  \& \ {\sf add\_array}) \ (pop\  \&\  pop\_array)):\Box int}& 
							\end{flalign*}} which reduces to:{\small\begin{flalign*}{\sf \Sigma}; \bullet\vdash&\mathtt{ let\{ (x_1\& s_1) {\ \sf be \ }(empty\  \& {\sf create()}),\ (x_2\& s_2) {\ \sf be\ } (push\  \& \ add\_array),\ \ (x_3\& s_3) {\ \sf be\ } (pop\  \& \ pop\_array)\}}&\\   
							&\mathtt{in \ (x_3(x_2\ 2 \ x_1) \ \&\  s_3*(s_2*\bar{2}*s_1)):\Box int}&
							\end{flalign*}}
						The last expression reduces to ($\beta$-reduction for {\sf let}):{\small\begin{flalign*}
							&{\sf \Sigma}; \bullet\vdash\mathtt{\ pop(push\ 2 \ empty)\ \&\  pop\_array*(add\_array*\bar{2}*empty):\Box int}
							\end{flalign*}}
						giving exactly the next step of the computation for the source expression.
						The good news is that the linker computes correctly the next step given any conforming set of implementations. 
						It is easy to see that given a {\sf list} implementation the very same process would produce a different computation step:{\small\begin{flalign*}
							&{\sf \Sigma}; \bullet\vdash\mathtt{\ pop(push\ 2 \ empty)\ \&\  pop\_list*(Cons*\bar{2}*[]):\Box int}
							\end{flalign*}}
					\end{enumerate}
					We conclude with some remarks that:
					\begin{itemize}
						\item The construction gives a mechanism of abstractions that works not only over different implementations in the
						same language but even for implementations in different (applicative) languages.
						\item We assumed in the example that the  two languages are based on the lambda calculus and implement a curried, higher-order function space. 
						It is easy to see that such host satisfies the requirements for the $\llbracket\bullet\rrbracket$ 
						(with $C_S, C_K$ being the $S, K$ combinators in $\lambda$ form  and $*$ translating to $\lambda$ application).
						\item
						Often, the host language of a foreign call is  not  a language that satisfies  such specifications. This situation occurs  when we have bindings from a functional language to a lower level language \footnote{In this setting the type signature of {\sf push} would be: $\mathtt{\sf int \times intstack\rightarrow instack}$}. 
						Such cases  can be captured by adding conjunction (and pairs), tuning the  specifications of $J$  accordingly and loosening the assumption that $\llbracket \bullet \rrbracket$
						is total on types.
						\item Introduction of  modal types is clearly relative to the $\llbracket\bullet \rrbracket$ function on types. 
						It would be interesting to consider examples where   $\llbracket\bullet \rrbracket$ is realized by non-trivial mappings such as $\llbracket A\supset B \rrbracket= !A \multimap B$
						from the embedding on intuitionistic logic to intuitionistic linear logic \cite{girard1987linear}.
						That will  showcase an example of   modality that works when lifting to a completely different logic or, correspondingly, to an essentially
						different computational model.
						\item Finally, it should be clear from the operational semantics and this example that we did not demand any equalities (or, reduction rules)  
						for the proofs in $J$, but mere existence of specific terms. This is in accordance to justification logic.  Analogously, we did not observe computation 
						in the host language but only the construction of the linkers as program transformers. We were careful, to say that our calculus corresponds to the dynamic 
						linking part of 
						separate compilation. This, of course, does not tell the whole story of program execution in such cases. Foreign function calls, return the control to the 
						client after the result gets calculated 
						in the external language. For example, the execution of the  program ${\texttt{pop (push 2 empty) + 2}}$ should ``escape'' the client 
						to compute the stack calls and then return
						for the last addition. Our modality is concerned  only with passing the control from the client to the host dynamically and, as such, is a $K$ 
						(non-factive) modality. Capturing the continuation of the computation and the return of the control back 
						to the source would  require a factive modality and a notion of ``reverse'' of the mapping $\llbracket\bullet\rrbracket$. 
						We would like to explore  such an extension in  future work.
						%Here the computation  mixes calling the  external implementation  $(\mathtt{st== empty})$ that -- in a full stack implementation -- would  provide for an equality check, computes its truth value externally and returns the control back to the client language  following the semantics of the $\mathtt{if}$ statement. The full logic for this can  be captured with a stronger modality (i.e. ``factive") that is work in progress. Nevertheless, our work is orthogonal and would correspond to dynamic linking aspect for such a system.
					\end{itemize}
					
					
					
					%\textcolor{green}{\texttt{push  empty\&}}}} $
					
					\section{Related and Future Work}
					\label{relat}
					Directly related work with our calculus, in the same fashion that justification logic and LP \cite{Artemov2001} are related to modal logic, is \cite{Bellin2001}.  The work in \cite{Bellin2001} provides a calculus for explicit assignments (substitutions) which is actually a sub-case of 
					{\sf Jcalc$^{-}$} with $\llbracket\bullet \rrbracket$ identity. This  sub-case  captures dynamic linking where the host language is the very same one; such need appears in languages with module mechanisms (i.e. implementation hiding and separate compilation within the very same language). In general, the judgmental approach to modality is heavily influenced by \cite{citeulike:5447115}. In a sense, our treatment of validity-as-explicit-provability also generalizes the approach there without having to commit to a ``factive" modality. Finally,  
					important results on programming paradigms related to justification logic have been obtained in \cite{ArtBon07LFCS,BONELLI2012935, bavera2010justification}. 
					Immediate future developments would be to interpret modal formulas of higher degree under the same principles. 
					This corresponds to dynamic linking in two or more steps (i.e., when the host becomes itself a client of another interface that is implemented dynamically in a third level and, so on). 
					Some preliminary results towards this 
					direction have been developed in \cite{DBLP:journals/entcs/PouliasisP14}. 
					%\nocite{Pfenning2009a, Pfenning2009b}
					

\begin{comment}					
\appendix
					
\label{appen}
\chapter{Appendix}
\subsection{Theorems}
					
					\begin{theorem}[Deduction Theorem for Validity Judgments]
						\label{deduct}
						Given any  $\Gamma,A,B \in {\sf Prop_0}$ then $\Gamma,x:A\vdash B \Longrightarrow \llbracket\Gamma\rrbracket\vdash\llbracket   A\supset B\rrbracket$. 
					\end{theorem}
					\begin{proof}
						The proof proceeds by induction on the derivations $\Gamma,A,B \in {\sf Prop_0}$. Note that the axiomatization of ${\llbracket\sf Prop_0\rrbracket}$ derives the 
						sequents:$\Delta\vdash\llbracket A \supset A\rrbracket$
						for any $\Delta\in {\sf \llbracket Prop_0 \rrbracket}$ (as in combinatory logic the $I$ combinator is derived from $SK$). This handles the reflection case. The rest of the cases are treated exactly as in the proof 
						of completeness of combinatorial axiomatization with respect to the natural deduction in intuitionistic logic. 
						Note that this theorem cannot be proven without the logical specification {\sf $Ax_1$, $Ax_2$}. I.e. it is exactly the requirements of the logical specification that ensure that all  interpretations  
						should be complete with respect to intuitionistic implication.
					\end{proof}
					\begin{lemma}[$\llbracket\bullet\rrbracket$Lifting Lemma]
						\label{bracklift}
						Given  $\Gamma,  A \in {\sf Prop_0}$ then $\Gamma\vdash   A \Longrightarrow \llbracket \Gamma\rrbracket \vdash \llbracket   A \rrbracket$. 
					\end{lemma}
					
					\begin{proof}
						The proof goes by induction on the derivations trivially for all the cases($\supset_{E_0}$ is treated using the ${\sf App}$ rule that internalizes Modus ponens). For the $\supset_{I_0}$ the previous theorem has to be used.
					\end{proof}

					\begin{proof}
						Assuming a derivation $\mathcal {D}$ ::$\Gamma\vdash   A$ from \ref{bracklift} there exists corresponding validity derivation $\mathcal{E}::\llbracket\Gamma\rrbracket\vdash\llbracket   A \rrbracket$. Using the two as premises in the $\Box_{IE}$ with $\Gamma := \Box \Gamma$ we obtain $\Box\Gamma\vdash\Box   A$.
					\end{proof}
					From the previous we get:

					%Let us show an inverse principle to the $\Box$ Lifting Lemma. We define for $A$ in {\sf Prop}:
					%\begin{flalign*}
					%\nonumber \downharpoonright P_i\ & =  P_i \\ \downharpoonright (A_1\supset A_2)&  =  \downharpoonright A_1 \supset \downharpoonright A_2 \\
					%\downharpoonright \Box A & = \downharpoonright A
					%\end{flalign*}
					%And the lifting of the $\downharpoonright$ over $\Gamma\in {\sf Prop}$. We get:
					\begin{theorem}[Collapse $\Box$ Lemma] If $\Box\Gamma\vdash \Box A$ for $\Gamma,A \in {\sf Prop_0}$ then $ \Gamma\vdash  A$.
					\end{theorem}
					\begin{theorem}[Weakening]
						For the N.D. system of {\sf Jcalc$^{-}$}, with $\Gamma, \Gamma^{\prime}\in {\sf Prop_0}$.
						\begin{enumerate}
							\item If  $\Gamma\vdash A$ then $\Gamma,\Gamma^{\prime}\vdash   A$.
							\item If  $\Box\Gamma\vdash \Box   A$ then $\Box\Gamma,\Box\Gamma^{\prime} \vdash \Box A$.
						\end{enumerate}
					\end{theorem} 
					\begin{proof}
						By induction on derivations for the first item. For the second item, given $\Box\Gamma\vdash \Box   A$ by the collapse lemma we get   $\Gamma\vdash   A$ which by the previous item
						gives $\Gamma,\Gamma^{\prime}\vdash   A$.  Using the lifting lemma we get $\llbracket \Gamma,\Gamma^{\prime}\rrbracket \vdash \llbracket  A \rrbracket$.
						Using the last two items we and the $\Box$ rule gives the result.
					\end{proof}
					
					\begin{theorem}[Contraction]
						\begin{enumerate}
							For the N.D. system of Jcalc, with $\Gamma,x:A,B\in {\sf Prop_0}$ 
							\item If  $\Gamma,x:A,x':A,\Gamma^{\prime}\vdash  B$ then $\Gamma,x:A,\Gamma^{\prime}\vdash   B$.
							\item If $\Box\Gamma,x:\Box A,x':\Box A,\Box\Gamma^{\prime}\vdash \Box B$ then $\Box\Gamma,x:\Box A,\Box \Gamma^{\prime}\vdash  \Box B$
						\end{enumerate}  
					\end{theorem}
					\begin{proof}
						Similarly with previous theorem.
					\end{proof}
					\begin{theorem}[Permutation]
						For the N.D. system of Jcalc, with $\Gamma\in {\sf Prop_0}$ and $\pi \Gamma$ the collection of permutations of $\Gamma$.
						\begin{enumerate}
							\item If  $\Gamma\vdash   A$ and $\Gamma^{\prime}\in \pi{\Gamma}$ then $\Gamma'\vdash   A$.
							\item If  $\Box\Gamma\vdash \Box   A$ then  $ \pi\Box\Gamma\vdash \Box   A$.
						\end{enumerate}
					\end{theorem}
					\begin{proof}
						As in the previous item.
					\end{proof}
					\begin{theorem}[Substitution Principle]
						The following hold for both kinds of judgments:
						\begin{enumerate}
							\item If  $\Gamma,x:A\vdash M: B$ and $\Gamma\vdash N: A$ then $\Gamma\vdash M[N/x]: B$ 
							\item If  $\llbracket\Gamma\rrbracket,s:\llbracket A \rrbracket \vdash {\sf J}: \llbracket B\rrbracket$ and 
							$\llbracket\Gamma\rrbracket\vdash {\sf J^{'}}: \llbracket B\rrbracket$ then  $\llbracket\Gamma\rrbracket\vdash  {\sf J[J^{'}/s]}\llbracket B\rrbracket$
						\end{enumerate}
					\end{theorem}
					All previous  theorems can actually be stated for proof terms too. We should discuss the following:
					\begin{theorem}[Deduction Theorem / Emulation of $\lambda$ abstraction]
						\label{deductterms}
						If $\Gamma, A\in {\sf Prop_0}$ and $\Gamma,x:A\vdash M:B$ then there exists ${\sf J}$ s.t.    $\llbracket\Gamma\rrbracket \vdash {\sf J}:\llbracket   A\supset B\rrbracket$.
					\end{theorem}
					\begin{lemma}[$\llbracket\bullet\rrbracket$Lifting Lemma for terms]
						\label{highorder}
						If $\Gamma, A \in {\sf Prop_0}$ and $\Gamma\vdash M: A$ then there exists ${\sf J}$ s.t. $\llbracket \Gamma\rrbracket \vdash {\sf J}:\llbracket   A \rrbracket$. 
					\end{lemma}
					In both theorems the existence of this ${\sf J,J^\prime}$ is algorithmic following the induction proof. 
					\subsection{Linking on the function space}
					The above mentioned algorithms permit  for translating $\lambda$ abstractions to polynomials of $S,K$ combinators which is a standard result in the literature. We do not give the details here but the translation is  syntax driven as it can be seen by the inductive nature of the proofs.
					
					Henceforth, we can generalize the construction in \ref{dlinker} so that it permits for dynamic linking of functions of the client 
					(with missing implementations) such as  $\mathtt{\lambda n:int. push\  n\  empty}$ dynamically given that the host actually implements 
					a higher-order function space (that is it implements the combinators $S,K$ in, say, own lambda calculus $\lambda^{J}$).
					Given implementations of $\mathtt{push\_impl}$, $\mathtt{empty\_impl}$ the linker produces an application expression 
					consisting of $\mathtt{push\_impl}$, $\mathtt{empty\_impl}$, $S$ and $K$.  
					The execution of the target expression will happen in the host after dereferencing  ${\sf push\_impl, empty\_impl}$ (dynamic part) 
					and the combinators $S,K$ (constant part) as, say, lambdas (e.g. $K=\lambda^{J} x.\lambda^{J} y. x$).
					
					\subsection{Gentzen's reduction Principle for $\Box$(General)}
					\label{redmult}
					\mbox{\footnotesize
						\begin{mathpar}
							\inferrule*[right=$  I_{\Box B} E_{\Box   A}^{x,s}$]{
								\inferrule*{}
								{\inferrule*[]{}{ \inferrule*[]	{\inferrule*[]{}{\PrTri{$D_1$} \\ \PrTri{$E_1$}}\\\\
											\inferrule*[]{}{ \ A_1\\ \ \qquad\ \ \  \llbracket   A_1\rrbracket}}{\Box   A_1 }}}\ldots 
								{\inferrule*[]{}{ \inferrule*[]	{\inferrule*[]{}{\PrTri{$D_i$} \\ \PrTri{$E_1$}}\\\\
											\inferrule*[]{}{\    A_i\\ \ \qquad \llbracket   A_i\rrbracket}}{\Box   A_i }}}
								\quad
								\inferrule*{}
								{\inferrule*[vdots=1.0em, right=$\vec{x}$]{ }{ A_1\dots A_i}\\\\
									\inferrule*[]{}{B}} 	   \qquad 
								\inferrule*{}
								{\inferrule*[vdots=1.0em, right=$\vec{s}$]{ }{\llbracket   A_1 \ldots A_i \rrbracket}\\\\
									\inferrule*[]{}{\llbracket B\rrbracket}} 	
							}
							{\Box B} 
						\end{mathpar}
					}
					$$\Longrightarrow_{R}$$
					\mbox{\footnotesize
						\begin{mathpar}
							\inferrule*[right=$I_{\Box B}$]{
								\inferrule*{}
								{\inferrule*[vdots=1.0em]{}{\PrTri{$D_1$}\ \PrTri{$D_i$} \\\\ A_1\ldots\ldots  \ \  A_i}\\\\
									\inferrule*[]{}{B}}
								\qquad 
								\inferrule*{}
								{\inferrule*[vdots=1.0em]
									{}{\PrTri{$E_1$} \PrTri{$E_i$}\\\\\llbracket   A_1\ldots\ldots A_i\rrbracket}\\\\
									\inferrule*[]{}{\llbracket B \rrbracket}} 
							}{\Box B}
							
						\end{mathpar}
					}
					\subsection{Notes on the cut elimination proof and normalization of natural deduction}
					\label{norm}
					Standardly, we add the bottom type and elimination rule in the natural deduction and show that in Jcalc + $\bot$: $\centernot\vdash\bot$. The addition goes as follows:
					
					\begin{mathpar}
						\inferrule*[right= Bot] { } {\bot \in {\sf Prop_0}}	
						\and
						\inferrule*[right= $E_\bot$] {{\Gamma\vdash\bot }\\ A\in {\sf Prop}} {\Gamma \vdash A}
					\end{mathpar}
					Our proof strategy follows directly \cite{pfenning2004automated}. We construct an intercalation calculus \cite{sieg1998normal} corresponding to the ${\sf Prop}$ fragment  with the following two judgments:
					\begin{itemize}
						\item[] $A\Uparrow$ for ``Proposition $A$ has normal deduction".
						\item[] $A^\downarrow$ for ``Proposition $A$ is extracted from hypothesis".
					\end{itemize}
					This calculus is, essentially, restricting the natural deduction to canonical derivations. The $\llbracket {\sf judgments} \rrbracket$ are not annotated and are directly ported from the natural deduction since we observe consistency in ${\sf Prop}$. 
					The construction is identical to \cite{pfenning2004automated} (Chapter 3) for the ${\sf Hypotheses},{\sf Coercion},\supset, \bot$ cases, we add the $\Box$ case.
					\begin{mathpar}
						\inferrule*[right=$\Gamma$-hyp]  {x: A\downarrow \in \Gamma^\downarrow}{ \Gamma^\downarrow\vdash^{-} A\downarrow}
						\and
						\inferrule*[right=$\downarrow\Uparrow$] {\Gamma^\downarrow\vdash^{-} A\downarrow}{\Gamma^\downarrow\vdash^{-} A \Uparrow}
						\and
						\inferrule*[right=$\supset$I$^{x}$] {\Gamma^\downarrow, x: A\downarrow\vdash^{-}  B\Uparrow} {\Gamma^\downarrow \vdash^{-}  A\supset  B\Uparrow}
						\inferrule*[right=$\supset$E] {{\Gamma^\downarrow\vdash^{-} A\supset  B \downarrow}\\{\Gamma^\downarrow\vdash^{-}  A\Uparrow}} {\Gamma^\downarrow\vdash^{-}   B\downarrow}
						%\and
						%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
						\and
						\inferrule*[right= $E_\bot$] {{\Gamma^{\downarrow}\vdash^{-}\bot\downarrow }\\ A\in {\sf Prop}} {\Gamma^{\downarrow}\vdash^{-} A\Uparrow}
						\and
						\inferrule*[right=$\Box_{IE}$ ] {{\Gamma^\downarrow\vdash\Box \Gamma^{\prime}\downarrow}\\{\Gamma'^\downarrow\vdash A\Uparrow }\\ {\llbracket \Gamma^{\prime} \rrbracket\vdash \llbracket A \rrbracket}}{ {\Gamma^\downarrow\vdash \Box A\Uparrow }}
					\end{mathpar}
					Where $\Gamma^\downarrow\vdash\Box \Gamma^{\prime}$ abbreviates $\forall A_i\in \Gamma'. \ \Gamma^{\downarrow}\vdash\Box A_i\downarrow$.
					We prove simultaneously by induction:
					\begin{theorem}[Soundness of Normal Deductions]
						The following hold:
						\begin{enumerate}
							\item If $\Gamma^\downarrow\vdash^{-} A\Uparrow$ then $\Gamma\vdash A$, and
							\item If $\Gamma^\downarrow\vdash^{-} A\downarrow $ then $\Gamma\vdash A$.
						\end{enumerate}
					\end{theorem}
					\begin{proof}
						Simultaneously by induction on derivations.
					\end{proof}
					It is easy to see that this restricted proof system $\centernot\vdash^{-} \bot\Uparrow$. It is hard to show its completeness to the non-restricted natural deduction ($\vdash + \bot_E$ of Jcalc) directly. For that reason we add a rule to make it complete ($\vdash^{+}$) preserving soundness and get a system of Annotated Deductions. We show the correspondence of the restricted system ($\vdash^{-}$) to a cut-free sequent calculus (${\sf JSeq}$), the correspondence of the extended system ($\vdash^{+}$) to ${\sf Jseq + Cut}$ and show cut elimination.\footnote{ In reality, the sequent calculus formulation is built exactly upon intuitions on the intercalation calculus. We refer the reader to the references.}
					
					To obtain completeness we add the rule:
					\begin{mathpar}
						\inferrule*[right=$\Uparrow\downarrow$] {\Gamma^\downarrow\vdash A\Uparrow} {\Gamma^\downarrow\vdash A\downarrow }
					\end{mathpar}
					We define $\vdash^{+} :=\   \ \ \vdash^{-} {\sf with} {\ \sf \Uparrow\downarrow}{\sf Rule}$.
					We show:
					\begin{theorem}[Soundness of Annotated Deductions]
						The following hold:
						\begin{enumerate}
							\item If $\Gamma^\downarrow\vdash^{+} A\Uparrow$ then $\Gamma\vdash A$, and
							\item If $\Gamma^\downarrow\vdash^{+} A\downarrow $ then $\Gamma\vdash A$.
						\end{enumerate}
					\end{theorem}
					\begin{proof}
						As previous item.
					\end{proof}
					
					\begin{theorem}[Completeness of Annotated Deductions]
						\label{compannot}
						The following hold:
						\begin{enumerate}
							\item If $\Gamma\vdash A$ then $\Gamma\downarrow\vdash^{+} A\Uparrow$, and
							\item If $\Gamma\vdash A$ then $\Gamma\downarrow\vdash^{+} A\downarrow$.
						\end{enumerate}
					\end{theorem}
					\begin{proof}
						By induction over the structure of the $\Gamma\vdash A$ derivation.
					\end{proof}
					
					Next we move with devising a sequent calculus formulation corresponding to normal proofs $\Gamma^{\downarrow}\vdash^{-}A\Uparrow$. The calculus that is given in the main body of this theorem. We repeat it here for completeness.
					\begin{mdframed}[nobreak=true,frametitle={\footnotesize Sequent Calculus ($\llbracket {\sf Prop_0} \rrbracket$)}]
						$$\begin{array}{l r}
						\Delta \Rightarrow \llbracket A\rrbracket:= & \exists \Delta'\in \pi(\Delta)\ \text{s.t} \   
						\Delta'\vdash \llbracket A \rrbracket \end{array}$$
						where $\pi(\Delta)$ is the collection of wellformed  $\llbracket {\sf Prop_0} \rrbracket$ contexts $\Delta'\vdash \llbracket {\sf wf}\rrbracket$  with some permutation of the multiset $\Delta$ as co--domain.
					\end{mdframed} 
					
					
					\begin{mdframed}[nobreak=true,frametitle={\footnotesize Sequent Calculus ({\sf Prop})}]
						\mbox{\small
							\begin{mathpar}
								\inferrule*[right=$Id$] { }{\Gamma, A  \Rightarrow A }
								
								\inferrule*[right=$\supset_L$] {{\Gamma, A\supset B, B \Rightarrow  C }\\ {\Gamma, A\supset B \Rightarrow A}} {\Gamma, A\supset B \Rightarrow  C}
								\and
								\inferrule*[right=$\supset_R$] {\Gamma, A \Rightarrow  B} {\Gamma \Rightarrow A\supset B}
								\and
								\inferrule*[right=$\bot_L$] { } {\Gamma, \bot \Rightarrow A}
								\and
								\inferrule*[right=$\Box_{LR}$] {{\Box\Gamma,\Gamma\Rightarrow A}\\{\llbracket\Gamma\rrbracket\Rightarrow \llbracket A \rrbracket }}{\Box\Gamma\Rightarrow \Box A}
								%\inferrule*[right=$\supset$E] {{\Turn {\Gamma} { A\supset  B}}\\{\Turn {\Gamma} { A}}} {\Turn {\Gamma} {   B}}
								%\and
								%\inferrule*[right=$\bot$E] {{\Turn {\Gamma} {\bot}}}{\Turn {\Gamma} {   A}}
							\end{mathpar}}
							%Where the  rule $\Box_{LR}$corresponds to $\Box_{IE}$ and relates the two kinds of sequents 
						\end{mdframed}
						We want to show correspondence of the sequent calculus  w.r.t normal proofs ($\vdash^{-}$).  Two lemmas are required to show soundness. 
						\begin{lemma}[Substitution principle for extractions]
							The following hold:
							\begin{enumerate}
								\item If $\Gamma_1^\downarrow, x:A^\downarrow,\Gamma_2^\downarrow\vdash^{-} B\Uparrow$ and\\$\Gamma_1^\downarrow\vdash^{-} A\Uparrow$ then  $\Gamma_1^\downarrow,\Gamma_2^\downarrow\vdash^{-} B\Uparrow$
								\item  If $\Gamma_1^\downarrow, x:A^\downarrow,\Gamma_2^\downarrow\vdash^{-} B\downarrow$ and $\Gamma_1^\downarrow\vdash^{-} A\downarrow$ then $\Gamma_1^\downarrow,\Gamma_2^\downarrow\vdash^{-} B\Uparrow$    
							\end{enumerate}
						\end{lemma}
						\begin{proof}
							Simultaneously by induction on the derivations $A\downarrow$ and $A\Uparrow$.
						\end{proof}
						And making use of the previous we can show, with ($\downharpoonright A$ defined previously):
						\begin{lemma}[Collapse principle for normal deductions]
							The following hold:
							\begin{enumerate}
								\item If $\Gamma^\downarrow,\vdash^{-}  A\Uparrow$ then $\downharpoonright\Gamma^\downarrow\vdash^{-} \downharpoonright A\Uparrow$   and,
								\item If $\Gamma^\downarrow\vdash^{-} A\downarrow$ then  $\downharpoonright\Gamma^\downarrow\vdash^{-} \downharpoonright A\downarrow$   
							\end{enumerate}
						\end{lemma}
						Using the previous lemmas and by induction we can show :
						\begin{theorem}[Soundness of the Sequent Calculus] 
							\label{soundnseq}
							If   $\Gamma\Rightarrow B$ then $\Gamma^\downarrow\vdash^{-} B\Uparrow$.
							
							
						\end{theorem}
						\begin{theorem}[Soundness of the Sequent Calculus with Cut] 
							
							If   $\Gamma\Rightarrow^{+} B$ then $\Gamma^\downarrow\vdash^{+} B\Uparrow$.
						\end{theorem}
						
						Next we define the $\Gamma\Rightarrow^{+} A$ as $\Gamma\Rightarrow A$ plus the rule:
						\begin{mathpar}
							\inferrule*[right=Cut]{{\Gamma\Rightarrow^{+} A}\\{\Gamma,A\Rightarrow^{+}B}}{\Gamma\Rightarrow^{+}B}
						\end{mathpar}
						\begin{proof}
							As before. The cut rule case is handled by the $\Uparrow\downarrow$ and substitution for extractions principle showcasing that the correspondence of the cut rule to the coercion from normal to extraction derivations.
						\end{proof}
						Standard structural properties (\textit{Weakening, Contraction}) to show completeness. We do not show these here but they hold.
						\begin{theorem}[Completeness of the Sequent Calculus] 
							\label{compseqcalc}
							The following hold:
							\begin{enumerate}
								\item If   $\Gamma^\downarrow\vdash^{-} B\Uparrow$ then $\Gamma\Rightarrow B$ and,
								\item 	If $\Gamma^\downarrow \vdash^{-} A\downarrow$ and $\Gamma,A\Rightarrow B$ then $\Gamma\Rightarrow B$   
							\end{enumerate}
							\begin{proof}
								Simultaneously by induction on the given derivations making use of the structural properties.
							\end{proof}
							Similarly we show for the extended systems.
							\begin{theorem}[Completeness of the Sequent Calculus with Cut] The following hold:
								\label{compseqcut}
								\begin{enumerate}
									\item If   $\Gamma^\downarrow\vdash^{+} B\Uparrow$ then  $\Gamma\Rightarrow^{+} B$ and,
									\item 	If $\Gamma^\downarrow \vdash^{+} A\downarrow$ and $\Gamma,A\Rightarrow^{+} B$ then $\Gamma\Rightarrow^{+} B$.   
								\end{enumerate}
							\end{theorem}
							\begin{proof}
								As before. The extra case is handled by the Cut rule.
							\end{proof}
						\end{theorem}
						After establishing the correspondence of $\vdash^{-}$ with $\Rightarrow$ and of $\vdash^{+}$ with $\Rightarrow^{+}$ we move on with:
						\begin{theorem}[Admissibility of Cut]
							If $\Gamma\Rightarrow A$ and $\Gamma,A\Rightarrow B$ then $\Gamma\Rightarrow B$.
						\end{theorem}
						The proof is by triple induction on the structure of the formula, and the given derivations and we leave it for a technical report. This gives easily:
						\begin{theorem}[Cut Elimination]
							If $\Gamma\Rightarrow^{+}A$ then $\Gamma\Rightarrow A$.
							
						\end{theorem}
						Which in turn gives us:
						\begin{theorem}[Normalization for Natural Deduction]
							\label{normalization}
							If $\Gamma\vdash A$ then $\Gamma^{\downarrow}\vdash^{-} A\Uparrow$
						\end{theorem}
						\begin{proof}
							From assumption $\Gamma \vdash A$ which by \ref{compannot} gives $\Gamma\vdash^{+} A\Uparrow$. By \ref{compseqcut} and Cut  Elimination we obtain $\Gamma\Rightarrow A$ which by  \ref{soundnseq} completes the proof.
						\end{proof}
						As a result we obtain:

						\begin{proof}
							By contradiction, assume $\vdash\bot$ then $\Rightarrow \bot$ which is not possible.
						\end{proof}
\end{comment}